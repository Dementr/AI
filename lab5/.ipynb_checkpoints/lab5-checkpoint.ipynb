{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e305852c",
   "metadata": {},
   "source": [
    "# Лабораторная работа 5\n",
    "\n",
    "   по теме\n",
    "                 \n",
    "   **Распознавание объектов на фотографиях**\n",
    "   \n",
    "   ****\n",
    "\n",
    "   Выполнил студент\n",
    "\n",
    "   Группы БСТ1801\n",
    "\n",
    "   Харатишвили Заза"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3825c28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Импорты\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0defa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 # на каждой итерации одновременно обрабатываем 32 обучающих образца\n",
    "num_epochs = 100 # количество итераций\n",
    "kernel_size = 3 # размер ядра в свертывающих слоях\n",
    "pool_size = 2 # размер подвыборки в слоях подвыборки\n",
    "conv_depth_1 = 32 # количество ядер в свертывающих слоях\n",
    "conv_depth_2 = 64 # увеличиваем в два раза после слоя подвыборки \n",
    "drop_prob_1 = 0.25 # убираем нейроны после слоя подвыборки с вероятностью 0.25\n",
    "drop_prob_2 = 0.5 # убираем нейроны после полносвязного слоя с вероятностью 0.5\n",
    "hidden_size = 512 # количество нейронов в полносвязном слое"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "314a4dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data() # получаем данные CIFAR-10 \n",
    "\n",
    "# 50000 данных для обучения, 10000 для тестирования, 10 классов картинок\n",
    "num_train, depth, height, width = X_train.shape\n",
    "num_test = X_test.shape[0]\n",
    "num_classes = np.unique(y_train).shape[0]\n",
    "\n",
    "# Приведем к виду с плавающей точкой\n",
    "X_train = X_train.astype('float32') \n",
    "X_test = X_test.astype('float32')\n",
    "# Преобразуем интетнсивность пикселей до [0 ,1]\n",
    "X_train /= np.max(X_train)\n",
    "X_test /= np.max(X_train) #делим на обучающее, тк нельзя показывать алгоритмам тестовые данные до окончания \n",
    "# процесса обучения\n",
    "\n",
    "# переводим в унитарный код\n",
    "Y_train = to_categorical(y_train, num_classes)\n",
    "Y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc1c671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  11/1407 [..............................] - ETA: 52s - loss: 2.3329 - accuracy: 0.1136"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(depth, height, width))\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "conv_1 = Convolution2D(conv_depth_1, (kernel_size, kernel_size), padding='same', activation='relu')(inp) #Сверточный слой\n",
    "conv_2 = Convolution2D(conv_depth_1, (kernel_size, kernel_size), padding='same', activation='relu')(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size), padding='same')(conv_2) # Слой подвыборки\n",
    "drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
    "conv_3 = Convolution2D(conv_depth_2, (kernel_size, kernel_size), padding='same', activation='relu')(drop_1)\n",
    "conv_4 = Convolution2D(conv_depth_2, (kernel_size, kernel_size), padding='same', activation='relu')(conv_3)\n",
    "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size), padding='same')(conv_4)\n",
    "drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "# Now flatten to 1D, apply FC -> ReLU (with dropout) -> softmax\n",
    "flat = Flatten()(drop_2) # Трансформируем в одномерный вектор\n",
    "hidden = Dense(hidden_size, activation='relu')(flat)\n",
    "drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "out = Dense(num_classes, activation='softmax')(drop_3)\n",
    "\n",
    "model = Model(inp, out) # Укажем слой входа и слой выхода\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "          verbose=1, validation_split=0.1) # Оставляем 10 процентов для тестирования\n",
    "# Оценим модель\n",
    "model.evaluate(X_test, Y_test, verbose=1) # Оценим обученную модель на тестовых данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bb9eef",
   "metadata": {},
   "source": [
    "Исследуем сеть без слоя Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bd8e2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1407/1407 [==============================] - 78s 55ms/step - loss: 1.4145 - accuracy: 0.4875 - val_loss: 1.0362 - val_accuracy: 0.6346\n",
      "Epoch 2/200\n",
      "1407/1407 [==============================] - 77s 55ms/step - loss: 0.9874 - accuracy: 0.6500 - val_loss: 0.8505 - val_accuracy: 0.7028\n",
      "Epoch 3/200\n",
      "1407/1407 [==============================] - 79s 56ms/step - loss: 0.7973 - accuracy: 0.7206 - val_loss: 0.7819 - val_accuracy: 0.7276\n",
      "Epoch 4/200\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.6519 - accuracy: 0.7711 - val_loss: 0.7798 - val_accuracy: 0.7382\n",
      "Epoch 5/200\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.5209 - accuracy: 0.8175 - val_loss: 0.7967 - val_accuracy: 0.7462\n",
      "Epoch 6/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.4094 - accuracy: 0.8566 - val_loss: 0.8652 - val_accuracy: 0.7416\n",
      "Epoch 7/200\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.3320 - accuracy: 0.8838 - val_loss: 0.9044 - val_accuracy: 0.7412\n",
      "Epoch 8/200\n",
      "1407/1407 [==============================] - 74s 52ms/step - loss: 0.2693 - accuracy: 0.9056 - val_loss: 0.9485 - val_accuracy: 0.7524\n",
      "Epoch 9/200\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.2234 - accuracy: 0.9218 - val_loss: 1.1295 - val_accuracy: 0.7482\n",
      "Epoch 10/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.2036 - accuracy: 0.9292 - val_loss: 1.1577 - val_accuracy: 0.7398\n",
      "Epoch 11/200\n",
      "1407/1407 [==============================] - 74s 52ms/step - loss: 0.1811 - accuracy: 0.9383 - val_loss: 1.2234 - val_accuracy: 0.7368\n",
      "Epoch 12/200\n",
      "1407/1407 [==============================] - 76s 54ms/step - loss: 0.1726 - accuracy: 0.9421 - val_loss: 1.0773 - val_accuracy: 0.7496\n",
      "Epoch 13/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.1579 - accuracy: 0.9471 - val_loss: 1.2339 - val_accuracy: 0.7384\n",
      "Epoch 14/200\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 0.1475 - accuracy: 0.9508 - val_loss: 1.4442 - val_accuracy: 0.7320\n",
      "Epoch 15/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.1474 - accuracy: 0.9500 - val_loss: 1.3349 - val_accuracy: 0.7326\n",
      "Epoch 16/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.1380 - accuracy: 0.9544 - val_loss: 1.4433 - val_accuracy: 0.7272\n",
      "Epoch 17/200\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.1265 - accuracy: 0.9584 - val_loss: 1.4188 - val_accuracy: 0.7440\n",
      "Epoch 18/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.1289 - accuracy: 0.9588 - val_loss: 1.5730 - val_accuracy: 0.7286\n",
      "Epoch 19/200\n",
      "1407/1407 [==============================] - 74s 52ms/step - loss: 0.1206 - accuracy: 0.9602 - val_loss: 1.4038 - val_accuracy: 0.7380\n",
      "Epoch 20/200\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.1210 - accuracy: 0.9617 - val_loss: 1.4604 - val_accuracy: 0.7448\n",
      "Epoch 21/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.1152 - accuracy: 0.9626 - val_loss: 1.5990 - val_accuracy: 0.7246\n",
      "Epoch 22/200\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 0.1207 - accuracy: 0.9612 - val_loss: 1.5224 - val_accuracy: 0.7252\n",
      "Epoch 23/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.1094 - accuracy: 0.9656 - val_loss: 1.6025 - val_accuracy: 0.7342\n",
      "Epoch 24/200\n",
      "1407/1407 [==============================] - 74s 52ms/step - loss: 0.1129 - accuracy: 0.9644 - val_loss: 1.4651 - val_accuracy: 0.7234\n",
      "Epoch 25/200\n",
      "1407/1407 [==============================] - 76s 54ms/step - loss: 0.0984 - accuracy: 0.9689 - val_loss: 1.6887 - val_accuracy: 0.7320\n",
      "Epoch 26/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.1131 - accuracy: 0.9646 - val_loss: 1.8695 - val_accuracy: 0.7296\n",
      "Epoch 27/200\n",
      "1407/1407 [==============================] - 74s 52ms/step - loss: 0.0995 - accuracy: 0.9695 - val_loss: 1.6045 - val_accuracy: 0.7460\n",
      "Epoch 28/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.1015 - accuracy: 0.9679 - val_loss: 1.7575 - val_accuracy: 0.7310\n",
      "Epoch 29/200\n",
      "1407/1407 [==============================] - 74s 52ms/step - loss: 0.1015 - accuracy: 0.9688 - val_loss: 1.6453 - val_accuracy: 0.7304\n",
      "Epoch 30/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.1023 - accuracy: 0.9683 - val_loss: 1.9162 - val_accuracy: 0.7330\n",
      "Epoch 31/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0991 - accuracy: 0.9706 - val_loss: 1.8688 - val_accuracy: 0.7340\n",
      "Epoch 32/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.1031 - accuracy: 0.9681 - val_loss: 1.5761 - val_accuracy: 0.7404\n",
      "Epoch 33/200\n",
      "1407/1407 [==============================] - 85s 60ms/step - loss: 0.0918 - accuracy: 0.9720 - val_loss: 1.8966 - val_accuracy: 0.7406\n",
      "Epoch 34/200\n",
      "1407/1407 [==============================] - 86s 61ms/step - loss: 0.1015 - accuracy: 0.9690 - val_loss: 1.9566 - val_accuracy: 0.7354\n",
      "Epoch 35/200\n",
      "1407/1407 [==============================] - 74s 52ms/step - loss: 0.0934 - accuracy: 0.9713 - val_loss: 2.0921 - val_accuracy: 0.7336\n",
      "Epoch 36/200\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.0984 - accuracy: 0.9695 - val_loss: 1.7230 - val_accuracy: 0.7204\n",
      "Epoch 37/200\n",
      "1407/1407 [==============================] - 79s 56ms/step - loss: 0.0967 - accuracy: 0.9711 - val_loss: 2.0627 - val_accuracy: 0.7242\n",
      "Epoch 38/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0904 - accuracy: 0.9722 - val_loss: 1.7327 - val_accuracy: 0.7360\n",
      "Epoch 39/200\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.0911 - accuracy: 0.9728 - val_loss: 1.8309 - val_accuracy: 0.7262\n",
      "Epoch 40/200\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.0953 - accuracy: 0.9727 - val_loss: 2.0391 - val_accuracy: 0.7116\n",
      "Epoch 41/200\n",
      "1407/1407 [==============================] - 75s 54ms/step - loss: 0.0858 - accuracy: 0.9748 - val_loss: 1.9274 - val_accuracy: 0.7300\n",
      "Epoch 42/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0880 - accuracy: 0.9741 - val_loss: 2.0055 - val_accuracy: 0.7348\n",
      "Epoch 43/200\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.0861 - accuracy: 0.9748 - val_loss: 2.3587 - val_accuracy: 0.7314\n",
      "Epoch 44/200\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.0943 - accuracy: 0.9723 - val_loss: 1.7933 - val_accuracy: 0.7330\n",
      "Epoch 45/200\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.0839 - accuracy: 0.9760 - val_loss: 1.7511 - val_accuracy: 0.7226\n",
      "Epoch 46/200\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 0.0938 - accuracy: 0.9727 - val_loss: 1.7561 - val_accuracy: 0.7352\n",
      "Epoch 47/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0891 - accuracy: 0.9738 - val_loss: 2.0152 - val_accuracy: 0.7334\n",
      "Epoch 48/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0835 - accuracy: 0.9752 - val_loss: 2.1524 - val_accuracy: 0.7344\n",
      "Epoch 49/200\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.0814 - accuracy: 0.9764 - val_loss: 2.2070 - val_accuracy: 0.7332\n",
      "Epoch 50/200\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 0.0929 - accuracy: 0.9734 - val_loss: 2.1116 - val_accuracy: 0.7400\n",
      "Epoch 51/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0799 - accuracy: 0.9774 - val_loss: 2.1606 - val_accuracy: 0.7202\n",
      "Epoch 52/200\n",
      "1407/1407 [==============================] - 74s 52ms/step - loss: 0.0784 - accuracy: 0.9772 - val_loss: 2.0934 - val_accuracy: 0.7284\n",
      "Epoch 53/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0985 - accuracy: 0.9740 - val_loss: 2.2407 - val_accuracy: 0.7220\n",
      "Epoch 54/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0842 - accuracy: 0.9773 - val_loss: 2.1333 - val_accuracy: 0.7254\n",
      "Epoch 55/200\n",
      "1407/1407 [==============================] - 74s 52ms/step - loss: 0.0841 - accuracy: 0.9763 - val_loss: 2.3729 - val_accuracy: 0.7244\n",
      "Epoch 56/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0821 - accuracy: 0.9767 - val_loss: 2.2075 - val_accuracy: 0.7368\n",
      "Epoch 57/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0805 - accuracy: 0.9775 - val_loss: 2.3928 - val_accuracy: 0.7260\n",
      "Epoch 58/200\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 0.0788 - accuracy: 0.9779 - val_loss: 2.4747 - val_accuracy: 0.7410\n",
      "Epoch 59/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0820 - accuracy: 0.9773 - val_loss: 1.9992 - val_accuracy: 0.7314\n",
      "Epoch 60/200\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.0857 - accuracy: 0.9762 - val_loss: 2.3034 - val_accuracy: 0.7174\n",
      "Epoch 61/200\n",
      "1407/1407 [==============================] - 75s 54ms/step - loss: 0.0796 - accuracy: 0.9777 - val_loss: 1.9095 - val_accuracy: 0.7244\n",
      "Epoch 62/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0816 - accuracy: 0.9770 - val_loss: 2.5425 - val_accuracy: 0.7358\n",
      "Epoch 63/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0889 - accuracy: 0.9761 - val_loss: 2.3336 - val_accuracy: 0.7262\n",
      "Epoch 64/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0781 - accuracy: 0.9791 - val_loss: 2.4327 - val_accuracy: 0.7254\n",
      "Epoch 65/200\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 0.0812 - accuracy: 0.9781 - val_loss: 2.4413 - val_accuracy: 0.7208\n",
      "Epoch 66/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0764 - accuracy: 0.9772 - val_loss: 2.2637 - val_accuracy: 0.7260\n",
      "Epoch 67/200\n",
      "1407/1407 [==============================] - 74s 52ms/step - loss: 0.0892 - accuracy: 0.9761 - val_loss: 2.8833 - val_accuracy: 0.7246\n",
      "Epoch 68/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0847 - accuracy: 0.9769 - val_loss: 2.6776 - val_accuracy: 0.7186\n",
      "Epoch 69/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0816 - accuracy: 0.9778 - val_loss: 2.7869 - val_accuracy: 0.7282\n",
      "Epoch 70/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0824 - accuracy: 0.9782 - val_loss: 2.2448 - val_accuracy: 0.7242\n",
      "Epoch 71/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0809 - accuracy: 0.9787 - val_loss: 2.2651 - val_accuracy: 0.7262\n",
      "Epoch 72/200\n",
      "1407/1407 [==============================] - 74s 52ms/step - loss: 0.0832 - accuracy: 0.9783 - val_loss: 2.4648 - val_accuracy: 0.7294\n",
      "Epoch 73/200\n",
      "1407/1407 [==============================] - 74s 52ms/step - loss: 0.0827 - accuracy: 0.9796 - val_loss: 2.8101 - val_accuracy: 0.7392\n",
      "Epoch 74/200\n",
      "1407/1407 [==============================] - 74s 52ms/step - loss: 0.0852 - accuracy: 0.9782 - val_loss: 2.5876 - val_accuracy: 0.7214\n",
      "Epoch 75/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0844 - accuracy: 0.9778 - val_loss: 2.4404 - val_accuracy: 0.7366\n",
      "Epoch 76/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0791 - accuracy: 0.9796 - val_loss: 3.2294 - val_accuracy: 0.7246\n",
      "Epoch 77/200\n",
      "1407/1407 [==============================] - 74s 52ms/step - loss: 0.0848 - accuracy: 0.9774 - val_loss: 2.5292 - val_accuracy: 0.7356\n",
      "Epoch 78/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0808 - accuracy: 0.9796 - val_loss: 2.7091 - val_accuracy: 0.7370\n",
      "Epoch 79/200\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 0.0869 - accuracy: 0.9781 - val_loss: 2.6524 - val_accuracy: 0.7224\n",
      "Epoch 80/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0849 - accuracy: 0.9788 - val_loss: 2.8114 - val_accuracy: 0.7250\n",
      "Epoch 81/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0821 - accuracy: 0.9792 - val_loss: 3.5852 - val_accuracy: 0.7140\n",
      "Epoch 82/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0887 - accuracy: 0.9771 - val_loss: 2.6678 - val_accuracy: 0.7290\n",
      "Epoch 83/200\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 0.0845 - accuracy: 0.9783 - val_loss: 3.0442 - val_accuracy: 0.7300\n",
      "Epoch 84/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0906 - accuracy: 0.9784 - val_loss: 2.1511 - val_accuracy: 0.7318\n",
      "Epoch 85/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0798 - accuracy: 0.9796 - val_loss: 2.1976 - val_accuracy: 0.7196\n",
      "Epoch 86/200\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.0833 - accuracy: 0.9796 - val_loss: 2.4835 - val_accuracy: 0.7144\n",
      "Epoch 87/200\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 0.0809 - accuracy: 0.9797 - val_loss: 2.8378 - val_accuracy: 0.7220\n",
      "Epoch 88/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0853 - accuracy: 0.9790 - val_loss: 3.1000 - val_accuracy: 0.7152\n",
      "Epoch 89/200\n",
      "1407/1407 [==============================] - 74s 52ms/step - loss: 0.0889 - accuracy: 0.9773 - val_loss: 3.1455 - val_accuracy: 0.7328\n",
      "Epoch 90/200\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.0891 - accuracy: 0.9785 - val_loss: 2.7124 - val_accuracy: 0.7300\n",
      "Epoch 91/200\n",
      "1407/1407 [==============================] - 76s 54ms/step - loss: 0.0805 - accuracy: 0.9800 - val_loss: 2.8710 - val_accuracy: 0.7264\n",
      "Epoch 92/200\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.0841 - accuracy: 0.9791 - val_loss: 2.7840 - val_accuracy: 0.7220\n",
      "Epoch 93/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0755 - accuracy: 0.9802 - val_loss: 3.0158 - val_accuracy: 0.7360\n",
      "Epoch 94/200\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.0921 - accuracy: 0.9778 - val_loss: 3.1953 - val_accuracy: 0.7222\n",
      "Epoch 95/200\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 0.0808 - accuracy: 0.9803 - val_loss: 3.1266 - val_accuracy: 0.7194\n",
      "Epoch 96/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0832 - accuracy: 0.9786 - val_loss: 3.1156 - val_accuracy: 0.7322\n",
      "Epoch 97/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0878 - accuracy: 0.9783 - val_loss: 3.9638 - val_accuracy: 0.7298\n",
      "Epoch 98/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0800 - accuracy: 0.9797 - val_loss: 3.6077 - val_accuracy: 0.7312\n",
      "Epoch 99/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0845 - accuracy: 0.9799 - val_loss: 2.9526 - val_accuracy: 0.7174\n",
      "Epoch 100/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0891 - accuracy: 0.9790 - val_loss: 3.3573 - val_accuracy: 0.7256\n",
      "Epoch 101/200\n",
      "1407/1407 [==============================] - 74s 52ms/step - loss: 0.0917 - accuracy: 0.9783 - val_loss: 2.4587 - val_accuracy: 0.7240\n",
      "Epoch 102/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0844 - accuracy: 0.9803 - val_loss: 2.7837 - val_accuracy: 0.7182\n",
      "Epoch 103/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0908 - accuracy: 0.9792 - val_loss: 2.4687 - val_accuracy: 0.7170\n",
      "Epoch 104/200\n",
      "1407/1407 [==============================] - 74s 52ms/step - loss: 0.0790 - accuracy: 0.9797 - val_loss: 3.0800 - val_accuracy: 0.7318\n",
      "Epoch 105/200\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.0877 - accuracy: 0.9782 - val_loss: 2.8337 - val_accuracy: 0.7334\n",
      "Epoch 106/200\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.0879 - accuracy: 0.9790 - val_loss: 2.8138 - val_accuracy: 0.7216\n",
      "Epoch 107/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0876 - accuracy: 0.9787 - val_loss: 2.8236 - val_accuracy: 0.7288\n",
      "Epoch 108/200\n",
      "1407/1407 [==============================] - 75s 54ms/step - loss: 0.0872 - accuracy: 0.9785 - val_loss: 3.2678 - val_accuracy: 0.7390\n",
      "Epoch 109/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0784 - accuracy: 0.9810 - val_loss: 3.8526 - val_accuracy: 0.7346\n",
      "Epoch 110/200\n",
      "1407/1407 [==============================] - 74s 52ms/step - loss: 0.0863 - accuracy: 0.9795 - val_loss: 2.9200 - val_accuracy: 0.7170\n",
      "Epoch 111/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 74s 52ms/step - loss: 0.0865 - accuracy: 0.9800 - val_loss: 2.8218 - val_accuracy: 0.7100\n",
      "Epoch 112/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0739 - accuracy: 0.9822 - val_loss: 3.9873 - val_accuracy: 0.7198\n",
      "Epoch 113/200\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 0.0962 - accuracy: 0.9771 - val_loss: 3.3830 - val_accuracy: 0.7278\n",
      "Epoch 114/200\n",
      "1407/1407 [==============================] - 71s 51ms/step - loss: 0.0866 - accuracy: 0.9801 - val_loss: 3.3440 - val_accuracy: 0.7312\n",
      "Epoch 115/200\n",
      "1407/1407 [==============================] - 72s 52ms/step - loss: 0.0862 - accuracy: 0.9803 - val_loss: 3.3114 - val_accuracy: 0.7262\n",
      "Epoch 116/200\n",
      "1407/1407 [==============================] - 74s 52ms/step - loss: 0.0945 - accuracy: 0.9785 - val_loss: 3.8280 - val_accuracy: 0.7270\n",
      "Epoch 117/200\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.0778 - accuracy: 0.9809 - val_loss: 3.8824 - val_accuracy: 0.7178\n",
      "Epoch 118/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0904 - accuracy: 0.9792 - val_loss: 3.4995 - val_accuracy: 0.7156\n",
      "Epoch 119/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0816 - accuracy: 0.9802 - val_loss: 3.3809 - val_accuracy: 0.7142\n",
      "Epoch 120/200\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.0914 - accuracy: 0.9792 - val_loss: 3.4522 - val_accuracy: 0.7254\n",
      "Epoch 121/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0956 - accuracy: 0.9783 - val_loss: 2.9535 - val_accuracy: 0.7238\n",
      "Epoch 122/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0874 - accuracy: 0.9800 - val_loss: 3.4690 - val_accuracy: 0.7238\n",
      "Epoch 123/200\n",
      "1407/1407 [==============================] - 74s 52ms/step - loss: 0.0842 - accuracy: 0.9810 - val_loss: 3.5706 - val_accuracy: 0.7120\n",
      "Epoch 124/200\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.0878 - accuracy: 0.9806 - val_loss: 3.6473 - val_accuracy: 0.7214\n",
      "Epoch 125/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0894 - accuracy: 0.9794 - val_loss: 2.7566 - val_accuracy: 0.7112\n",
      "Epoch 126/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0902 - accuracy: 0.9794 - val_loss: 2.7871 - val_accuracy: 0.7118\n",
      "Epoch 127/200\n",
      "1407/1407 [==============================] - 74s 52ms/step - loss: 0.0840 - accuracy: 0.9807 - val_loss: 3.4998 - val_accuracy: 0.7310\n",
      "Epoch 128/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0965 - accuracy: 0.9780 - val_loss: 3.2399 - val_accuracy: 0.7210\n",
      "Epoch 129/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0932 - accuracy: 0.9797 - val_loss: 3.2788 - val_accuracy: 0.7246\n",
      "Epoch 130/200\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.0897 - accuracy: 0.9794 - val_loss: 2.9564 - val_accuracy: 0.7218\n",
      "Epoch 131/200\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.0926 - accuracy: 0.9792 - val_loss: 2.7114 - val_accuracy: 0.7204\n",
      "Epoch 132/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0896 - accuracy: 0.9801 - val_loss: 3.3421 - val_accuracy: 0.7332\n",
      "Epoch 133/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0849 - accuracy: 0.9806 - val_loss: 4.2542 - val_accuracy: 0.7278\n",
      "Epoch 134/200\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.0873 - accuracy: 0.9805 - val_loss: 3.7613 - val_accuracy: 0.7268\n",
      "Epoch 135/200\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.0946 - accuracy: 0.9786 - val_loss: 2.5820 - val_accuracy: 0.7274\n",
      "Epoch 136/200\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 0.0996 - accuracy: 0.9783 - val_loss: 2.9293 - val_accuracy: 0.7148\n",
      "Epoch 137/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0905 - accuracy: 0.9802 - val_loss: 3.2190 - val_accuracy: 0.7210\n",
      "Epoch 138/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0930 - accuracy: 0.9783 - val_loss: 3.5743 - val_accuracy: 0.7220\n",
      "Epoch 139/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0953 - accuracy: 0.9790 - val_loss: 3.3693 - val_accuracy: 0.7072\n",
      "Epoch 140/200\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 0.0936 - accuracy: 0.9791 - val_loss: 3.8157 - val_accuracy: 0.7252\n",
      "Epoch 141/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0944 - accuracy: 0.9796 - val_loss: 3.3642 - val_accuracy: 0.7174\n",
      "Epoch 142/200\n",
      "1407/1407 [==============================] - 74s 52ms/step - loss: 0.0986 - accuracy: 0.9782 - val_loss: 3.7837 - val_accuracy: 0.7206\n",
      "Epoch 143/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0893 - accuracy: 0.9801 - val_loss: 5.1398 - val_accuracy: 0.7258\n",
      "Epoch 144/200\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 0.1063 - accuracy: 0.9779 - val_loss: 4.4378 - val_accuracy: 0.7132\n",
      "Epoch 145/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0989 - accuracy: 0.9786 - val_loss: 3.0434 - val_accuracy: 0.7046\n",
      "Epoch 146/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0875 - accuracy: 0.9800 - val_loss: 3.2435 - val_accuracy: 0.7262\n",
      "Epoch 147/200\n",
      "1407/1407 [==============================] - 74s 52ms/step - loss: 0.0998 - accuracy: 0.9790 - val_loss: 3.8799 - val_accuracy: 0.7202\n",
      "Epoch 148/200\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.0978 - accuracy: 0.9786 - val_loss: 2.5045 - val_accuracy: 0.6842\n",
      "Epoch 149/200\n",
      "1407/1407 [==============================] - 74s 52ms/step - loss: 0.0944 - accuracy: 0.9803 - val_loss: 3.4344 - val_accuracy: 0.7258\n",
      "Epoch 150/200\n",
      "1407/1407 [==============================] - 74s 52ms/step - loss: 0.0941 - accuracy: 0.9792 - val_loss: 4.4213 - val_accuracy: 0.7270\n",
      "Epoch 151/200\n",
      "1407/1407 [==============================] - 74s 52ms/step - loss: 0.1025 - accuracy: 0.9774 - val_loss: 3.8758 - val_accuracy: 0.7266\n",
      "Epoch 152/200\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.0831 - accuracy: 0.9809 - val_loss: 4.3541 - val_accuracy: 0.7256\n",
      "Epoch 153/200\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.1032 - accuracy: 0.9779 - val_loss: 4.2448 - val_accuracy: 0.7292\n",
      "Epoch 154/200\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.0945 - accuracy: 0.9799 - val_loss: 4.2540 - val_accuracy: 0.7050\n",
      "Epoch 155/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.1112 - accuracy: 0.9774 - val_loss: 4.1729 - val_accuracy: 0.7266\n",
      "Epoch 156/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.1013 - accuracy: 0.9793 - val_loss: 4.1586 - val_accuracy: 0.7226\n",
      "Epoch 157/200\n",
      "1407/1407 [==============================] - 78s 55ms/step - loss: 0.1141 - accuracy: 0.9758 - val_loss: 5.8297 - val_accuracy: 0.6934\n",
      "Epoch 158/200\n",
      "  73/1407 [>.............................] - ETA: 1:07 - loss: 0.1089 - accuracy: 0.9786"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(inp, out) \u001b[38;5;66;03m# Укажем слой входа и слой выхода\u001b[39;00m\n\u001b[0;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 22\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m          \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(depth, height, width))\n",
    "# Conv [32] -> Conv [32] -> Pool\n",
    "conv_1 = Convolution2D(conv_depth_1, (kernel_size, kernel_size), padding='same', activation='relu')(inp)\n",
    "conv_2 = Convolution2D(conv_depth_1, (kernel_size, kernel_size), padding='same', activation='relu')(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size), padding='same')(conv_2)\n",
    "\n",
    "# Conv [64] -> Conv [64] -> Pool\n",
    "conv_3 = Convolution2D(conv_depth_2, (kernel_size, kernel_size), padding='same', activation='relu')(pool_1)\n",
    "conv_4 = Convolution2D(conv_depth_2, (kernel_size, kernel_size), padding='same', activation='relu')(conv_3)\n",
    "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size), padding='same')(conv_4)\n",
    "\n",
    "# Now flatten to 1D, apply FC -> ReLU -> softmax\n",
    "flat = Flatten()(conv_4) # Трансформируем в одномерный вектор\n",
    "hidden = Dense(hidden_size, activation='relu')(flat)\n",
    "drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "out = Dense(num_classes, activation='softmax')(drop_3)\n",
    "\n",
    "model = Model(inp, out) # Укажем слой входа и слой выхода\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "          verbose=1, validation_split=0.1) # Оставляем 10 процентов для тестирования\n",
    "\n",
    "model.evaluate(X_test, Y_test, verbose=1) # Оценим обученную модель на тестовых данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2acc916",
   "metadata": {},
   "source": [
    "Уменьшим размер ядра свертки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b18966d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'depth' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m kernel_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# размер ядра в свертывающих слоях\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m inp \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[43mdepth\u001b[49m, height, width))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m conv_1 \u001b[38;5;241m=\u001b[39m Convolution2D(conv_depth_1, (kernel_size, kernel_size), padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(inp)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'depth' is not defined"
     ]
    }
   ],
   "source": [
    "kernel_size = 1 # размер ядра в свертывающих слоях\n",
    "\n",
    "inp = Input(shape=(depth, height, width))\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "conv_1 = Convolution2D(conv_depth_1, (kernel_size, kernel_size), padding='same', activation='relu')(inp)\n",
    "conv_2 = Convolution2D(conv_depth_1, (kernel_size, kernel_size), padding='same', activation='relu')(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size), padding='same')(conv_2)\n",
    "drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
    "conv_3 = Convolution2D(conv_depth_2, (kernel_size, kernel_size), padding='same', activation='relu')(drop_1)\n",
    "conv_4 = Convolution2D(conv_depth_2, (kernel_size, kernel_size), padding='same', activation='relu')(conv_3)\n",
    "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size), padding='same')(conv_4)\n",
    "drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "# Now flatten to 1D, apply FC -> ReLU (with dropout) -> softmax\n",
    "flat = Flatten()(drop_2) # Трансформируем в одномерный вектор\n",
    "hidden = Dense(hidden_size, activation='relu')(flat)\n",
    "drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "out = Dense(num_classes, activation='softmax')(drop_3)\n",
    "\n",
    "model = Model(inp, out) # Укажем слой входа и слой выхода\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "          verbose=1, validation_split=0.1) # Оставляем 10 процентов для тестирования\n",
    "\n",
    "model.evaluate(X_test, Y_test, verbose=1) # Оценим обученную модель на тестовых данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a76a7d7",
   "metadata": {},
   "source": [
    "Увеличим размер ядра свертки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bac18fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1407/1407 [==============================] - 84s 59ms/step - loss: 1.5093 - accuracy: 0.4517 - val_loss: 1.0760 - val_accuracy: 0.6204\n",
      "Epoch 2/200\n",
      "1407/1407 [==============================] - 82s 59ms/step - loss: 1.0670 - accuracy: 0.6202 - val_loss: 0.8593 - val_accuracy: 0.6980\n",
      "Epoch 3/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.9140 - accuracy: 0.6776 - val_loss: 0.7771 - val_accuracy: 0.7310\n",
      "Epoch 4/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.8141 - accuracy: 0.7104 - val_loss: 0.7325 - val_accuracy: 0.7482\n",
      "Epoch 5/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.7439 - accuracy: 0.7392 - val_loss: 0.7254 - val_accuracy: 0.7522\n",
      "Epoch 6/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.6958 - accuracy: 0.7522 - val_loss: 0.6709 - val_accuracy: 0.7724\n",
      "Epoch 7/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.6472 - accuracy: 0.7712 - val_loss: 0.6758 - val_accuracy: 0.7706\n",
      "Epoch 8/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.6077 - accuracy: 0.7876 - val_loss: 0.6732 - val_accuracy: 0.7762\n",
      "Epoch 9/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.5780 - accuracy: 0.7968 - val_loss: 0.7037 - val_accuracy: 0.7618\n",
      "Epoch 10/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.5434 - accuracy: 0.8064 - val_loss: 0.6544 - val_accuracy: 0.7854\n",
      "Epoch 11/200\n",
      "1407/1407 [==============================] - 83s 59ms/step - loss: 0.5196 - accuracy: 0.8169 - val_loss: 0.6818 - val_accuracy: 0.7790\n",
      "Epoch 12/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.5030 - accuracy: 0.8222 - val_loss: 0.6676 - val_accuracy: 0.7832\n",
      "Epoch 13/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.4820 - accuracy: 0.8318 - val_loss: 0.7305 - val_accuracy: 0.7638\n",
      "Epoch 14/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.4642 - accuracy: 0.8357 - val_loss: 0.6818 - val_accuracy: 0.7850\n",
      "Epoch 15/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.4463 - accuracy: 0.8428 - val_loss: 0.6623 - val_accuracy: 0.7894\n",
      "Epoch 16/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.4396 - accuracy: 0.8442 - val_loss: 0.6926 - val_accuracy: 0.7888\n",
      "Epoch 17/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.4214 - accuracy: 0.8519 - val_loss: 0.6910 - val_accuracy: 0.7860\n",
      "Epoch 18/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.4115 - accuracy: 0.8568 - val_loss: 0.6582 - val_accuracy: 0.7892\n",
      "Epoch 19/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.4002 - accuracy: 0.8589 - val_loss: 0.7005 - val_accuracy: 0.7964\n",
      "Epoch 20/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.3984 - accuracy: 0.8616 - val_loss: 0.7436 - val_accuracy: 0.7868\n",
      "Epoch 21/200\n",
      "1407/1407 [==============================] - 81s 57ms/step - loss: 0.3875 - accuracy: 0.8649 - val_loss: 0.7005 - val_accuracy: 0.7920\n",
      "Epoch 22/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.3749 - accuracy: 0.8678 - val_loss: 0.6880 - val_accuracy: 0.7918\n",
      "Epoch 23/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.3664 - accuracy: 0.8722 - val_loss: 0.6911 - val_accuracy: 0.7966\n",
      "Epoch 24/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.3603 - accuracy: 0.8754 - val_loss: 0.6825 - val_accuracy: 0.7894\n",
      "Epoch 25/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.3625 - accuracy: 0.8719 - val_loss: 0.7181 - val_accuracy: 0.7952\n",
      "Epoch 26/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.3498 - accuracy: 0.8766 - val_loss: 0.7334 - val_accuracy: 0.7892\n",
      "Epoch 27/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.3440 - accuracy: 0.8796 - val_loss: 0.6890 - val_accuracy: 0.7926\n",
      "Epoch 28/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.3417 - accuracy: 0.8819 - val_loss: 0.7289 - val_accuracy: 0.7898\n",
      "Epoch 29/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.3384 - accuracy: 0.8836 - val_loss: 0.6763 - val_accuracy: 0.7930\n",
      "Epoch 30/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.3279 - accuracy: 0.8865 - val_loss: 0.7125 - val_accuracy: 0.8000\n",
      "Epoch 31/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.3266 - accuracy: 0.8861 - val_loss: 0.7027 - val_accuracy: 0.7918\n",
      "Epoch 32/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.3233 - accuracy: 0.8877 - val_loss: 0.7292 - val_accuracy: 0.7980\n",
      "Epoch 33/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.3324 - accuracy: 0.8867 - val_loss: 0.7047 - val_accuracy: 0.7920\n",
      "Epoch 34/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.3210 - accuracy: 0.8894 - val_loss: 0.7666 - val_accuracy: 0.7892\n",
      "Epoch 35/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.3101 - accuracy: 0.8922 - val_loss: 0.7202 - val_accuracy: 0.7998\n",
      "Epoch 36/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.3089 - accuracy: 0.8935 - val_loss: 0.7148 - val_accuracy: 0.7980\n",
      "Epoch 37/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.3042 - accuracy: 0.8959 - val_loss: 0.7352 - val_accuracy: 0.7958\n",
      "Epoch 38/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.3069 - accuracy: 0.8959 - val_loss: 0.7772 - val_accuracy: 0.7916\n",
      "Epoch 39/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.2991 - accuracy: 0.8983 - val_loss: 0.7451 - val_accuracy: 0.7866\n",
      "Epoch 40/200\n",
      "1407/1407 [==============================] - 83s 59ms/step - loss: 0.2996 - accuracy: 0.8969 - val_loss: 0.8195 - val_accuracy: 0.7790\n",
      "Epoch 41/200\n",
      "1407/1407 [==============================] - 81s 57ms/step - loss: 0.2933 - accuracy: 0.9005 - val_loss: 0.7337 - val_accuracy: 0.8024\n",
      "Epoch 42/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2891 - accuracy: 0.9023 - val_loss: 0.7311 - val_accuracy: 0.7950\n",
      "Epoch 43/200\n",
      "1407/1407 [==============================] - 81s 57ms/step - loss: 0.2854 - accuracy: 0.9030 - val_loss: 0.7160 - val_accuracy: 0.7936\n",
      "Epoch 44/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2894 - accuracy: 0.9014 - val_loss: 0.7356 - val_accuracy: 0.8032\n",
      "Epoch 45/200\n",
      "1407/1407 [==============================] - 81s 57ms/step - loss: 0.2857 - accuracy: 0.9052 - val_loss: 0.7326 - val_accuracy: 0.7946\n",
      "Epoch 46/200\n",
      "1407/1407 [==============================] - 81s 57ms/step - loss: 0.2853 - accuracy: 0.9019 - val_loss: 0.7506 - val_accuracy: 0.7884\n",
      "Epoch 47/200\n",
      "1407/1407 [==============================] - 81s 57ms/step - loss: 0.2812 - accuracy: 0.9045 - val_loss: 0.7693 - val_accuracy: 0.7860\n",
      "Epoch 48/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2831 - accuracy: 0.9043 - val_loss: 0.7039 - val_accuracy: 0.7904\n",
      "Epoch 49/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2827 - accuracy: 0.9056 - val_loss: 0.7611 - val_accuracy: 0.7984\n",
      "Epoch 50/200\n",
      "1407/1407 [==============================] - 81s 57ms/step - loss: 0.2763 - accuracy: 0.9050 - val_loss: 0.8387 - val_accuracy: 0.8034\n",
      "Epoch 51/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2763 - accuracy: 0.9064 - val_loss: 0.8012 - val_accuracy: 0.7910\n",
      "Epoch 52/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2667 - accuracy: 0.9105 - val_loss: 0.8062 - val_accuracy: 0.7970\n",
      "Epoch 53/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2712 - accuracy: 0.9100 - val_loss: 0.7554 - val_accuracy: 0.7962\n",
      "Epoch 54/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.2655 - accuracy: 0.9118 - val_loss: 0.7250 - val_accuracy: 0.7914\n",
      "Epoch 55/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.2720 - accuracy: 0.9083 - val_loss: 0.8182 - val_accuracy: 0.7900\n",
      "Epoch 56/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2705 - accuracy: 0.9096 - val_loss: 0.8561 - val_accuracy: 0.7942\n",
      "Epoch 57/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.2672 - accuracy: 0.9108 - val_loss: 0.7951 - val_accuracy: 0.7940\n",
      "Epoch 58/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.2590 - accuracy: 0.9127 - val_loss: 0.7701 - val_accuracy: 0.7998\n",
      "Epoch 59/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.2558 - accuracy: 0.9127 - val_loss: 0.7976 - val_accuracy: 0.7922\n",
      "Epoch 60/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2634 - accuracy: 0.9125 - val_loss: 0.7604 - val_accuracy: 0.7906\n",
      "Epoch 61/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2610 - accuracy: 0.9139 - val_loss: 0.8064 - val_accuracy: 0.7984\n",
      "Epoch 62/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.2634 - accuracy: 0.9110 - val_loss: 0.7947 - val_accuracy: 0.8016\n",
      "Epoch 63/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2518 - accuracy: 0.9157 - val_loss: 0.8369 - val_accuracy: 0.7888\n",
      "Epoch 64/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2586 - accuracy: 0.9141 - val_loss: 0.8117 - val_accuracy: 0.8006\n",
      "Epoch 65/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2632 - accuracy: 0.9145 - val_loss: 0.8209 - val_accuracy: 0.7948\n",
      "Epoch 66/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.2569 - accuracy: 0.9149 - val_loss: 0.7845 - val_accuracy: 0.7960\n",
      "Epoch 67/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.2526 - accuracy: 0.9177 - val_loss: 0.7943 - val_accuracy: 0.7980\n",
      "Epoch 68/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.2522 - accuracy: 0.9160 - val_loss: 0.8172 - val_accuracy: 0.7948\n",
      "Epoch 69/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.2467 - accuracy: 0.9184 - val_loss: 0.8848 - val_accuracy: 0.7900\n",
      "Epoch 70/200\n",
      "1407/1407 [==============================] - 82s 59ms/step - loss: 0.2542 - accuracy: 0.9145 - val_loss: 0.7848 - val_accuracy: 0.7950\n",
      "Epoch 71/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.2471 - accuracy: 0.9180 - val_loss: 0.8356 - val_accuracy: 0.7956\n",
      "Epoch 72/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.2428 - accuracy: 0.9204 - val_loss: 0.7931 - val_accuracy: 0.7976\n",
      "Epoch 73/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.2533 - accuracy: 0.9154 - val_loss: 0.8394 - val_accuracy: 0.8010\n",
      "Epoch 74/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.2504 - accuracy: 0.9171 - val_loss: 0.8123 - val_accuracy: 0.7996\n",
      "Epoch 75/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2505 - accuracy: 0.9173 - val_loss: 0.7336 - val_accuracy: 0.8038\n",
      "Epoch 76/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2483 - accuracy: 0.9184 - val_loss: 0.8066 - val_accuracy: 0.8006\n",
      "Epoch 77/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.2430 - accuracy: 0.9202 - val_loss: 0.8347 - val_accuracy: 0.7930\n",
      "Epoch 78/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.2435 - accuracy: 0.9190 - val_loss: 0.7717 - val_accuracy: 0.8062\n",
      "Epoch 79/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2448 - accuracy: 0.9199 - val_loss: 0.8188 - val_accuracy: 0.8022\n",
      "Epoch 80/200\n",
      "1407/1407 [==============================] - 82s 59ms/step - loss: 0.2350 - accuracy: 0.9241 - val_loss: 0.8159 - val_accuracy: 0.7974\n",
      "Epoch 81/200\n",
      "1407/1407 [==============================] - 81s 57ms/step - loss: 0.2375 - accuracy: 0.9212 - val_loss: 0.7738 - val_accuracy: 0.7926\n",
      "Epoch 82/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2462 - accuracy: 0.9198 - val_loss: 0.8676 - val_accuracy: 0.7998\n",
      "Epoch 83/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2384 - accuracy: 0.9226 - val_loss: 0.8840 - val_accuracy: 0.8018\n",
      "Epoch 84/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2348 - accuracy: 0.9237 - val_loss: 0.9410 - val_accuracy: 0.8040\n",
      "Epoch 85/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2415 - accuracy: 0.9196 - val_loss: 0.8265 - val_accuracy: 0.8004\n",
      "Epoch 86/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2353 - accuracy: 0.9221 - val_loss: 0.8061 - val_accuracy: 0.8060\n",
      "Epoch 87/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2342 - accuracy: 0.9223 - val_loss: 0.8180 - val_accuracy: 0.8014\n",
      "Epoch 88/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2340 - accuracy: 0.9225 - val_loss: 0.8335 - val_accuracy: 0.8016\n",
      "Epoch 89/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2446 - accuracy: 0.9212 - val_loss: 0.8681 - val_accuracy: 0.7932\n",
      "Epoch 90/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2389 - accuracy: 0.9216 - val_loss: 0.8308 - val_accuracy: 0.7934\n",
      "Epoch 91/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2273 - accuracy: 0.9249 - val_loss: 0.8475 - val_accuracy: 0.7988\n",
      "Epoch 92/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.2389 - accuracy: 0.9224 - val_loss: 0.7859 - val_accuracy: 0.8014\n",
      "Epoch 93/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2373 - accuracy: 0.9224 - val_loss: 0.8675 - val_accuracy: 0.7988\n",
      "Epoch 94/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.2301 - accuracy: 0.9255 - val_loss: 0.8979 - val_accuracy: 0.8020\n",
      "Epoch 95/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2320 - accuracy: 0.9230 - val_loss: 0.9055 - val_accuracy: 0.7934\n",
      "Epoch 96/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.2299 - accuracy: 0.9268 - val_loss: 0.9026 - val_accuracy: 0.8012\n",
      "Epoch 97/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.2156 - accuracy: 0.9302 - val_loss: 0.9206 - val_accuracy: 0.7990\n",
      "Epoch 98/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2272 - accuracy: 0.9267 - val_loss: 0.7914 - val_accuracy: 0.8018\n",
      "Epoch 99/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2251 - accuracy: 0.9264 - val_loss: 0.8910 - val_accuracy: 0.8016\n",
      "Epoch 100/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2306 - accuracy: 0.9257 - val_loss: 0.8963 - val_accuracy: 0.7986\n",
      "Epoch 101/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2220 - accuracy: 0.9290 - val_loss: 0.8498 - val_accuracy: 0.8002\n",
      "Epoch 102/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2260 - accuracy: 0.9255 - val_loss: 0.8075 - val_accuracy: 0.8066\n",
      "Epoch 103/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2191 - accuracy: 0.9283 - val_loss: 0.9742 - val_accuracy: 0.7920\n",
      "Epoch 104/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2303 - accuracy: 0.9258 - val_loss: 0.8635 - val_accuracy: 0.8058\n",
      "Epoch 105/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2189 - accuracy: 0.9289 - val_loss: 0.9204 - val_accuracy: 0.8000\n",
      "Epoch 106/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2323 - accuracy: 0.9261 - val_loss: 0.8241 - val_accuracy: 0.7938\n",
      "Epoch 107/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2367 - accuracy: 0.9241 - val_loss: 0.8329 - val_accuracy: 0.7878\n",
      "Epoch 108/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2247 - accuracy: 0.9271 - val_loss: 0.8259 - val_accuracy: 0.7994\n",
      "Epoch 109/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2265 - accuracy: 0.9277 - val_loss: 0.8733 - val_accuracy: 0.7986\n",
      "Epoch 110/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2277 - accuracy: 0.9272 - val_loss: 0.8733 - val_accuracy: 0.8024\n",
      "Epoch 111/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2267 - accuracy: 0.9263 - val_loss: 0.8830 - val_accuracy: 0.7972\n",
      "Epoch 112/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2229 - accuracy: 0.9269 - val_loss: 0.8693 - val_accuracy: 0.7976\n",
      "Epoch 113/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2200 - accuracy: 0.9288 - val_loss: 0.8939 - val_accuracy: 0.7904\n",
      "Epoch 114/200\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.2175 - accuracy: 0.9309 - val_loss: 0.8975 - val_accuracy: 0.7934\n",
      "Epoch 115/200\n",
      "1407/1407 [==============================] - 81s 58ms/step - loss: 0.2172 - accuracy: 0.9297 - val_loss: 0.9276 - val_accuracy: 0.7994\n",
      "Epoch 116/200\n",
      "1407/1407 [==============================] - 82s 59ms/step - loss: 0.2284 - accuracy: 0.9280 - val_loss: 0.8532 - val_accuracy: 0.8006\n",
      "Epoch 117/200\n",
      "1407/1407 [==============================] - 84s 59ms/step - loss: 0.2207 - accuracy: 0.9284 - val_loss: 0.8689 - val_accuracy: 0.7982\n",
      "Epoch 118/200\n",
      "1407/1407 [==============================] - 85s 61ms/step - loss: 0.2200 - accuracy: 0.9281 - val_loss: 0.8669 - val_accuracy: 0.7976\n",
      "Epoch 119/200\n",
      "1407/1407 [==============================] - 85s 61ms/step - loss: 0.2203 - accuracy: 0.9294 - val_loss: 0.9120 - val_accuracy: 0.8024\n",
      "Epoch 120/200\n",
      "1407/1407 [==============================] - 84s 60ms/step - loss: 0.2195 - accuracy: 0.9285 - val_loss: 0.8940 - val_accuracy: 0.7950\n",
      "Epoch 121/200\n",
      "1407/1407 [==============================] - 82s 59ms/step - loss: 0.2151 - accuracy: 0.9313 - val_loss: 0.9162 - val_accuracy: 0.8022\n",
      "Epoch 122/200\n",
      "1407/1407 [==============================] - 85s 60ms/step - loss: 0.2130 - accuracy: 0.9317 - val_loss: 0.8808 - val_accuracy: 0.7916\n",
      "Epoch 123/200\n",
      "1407/1407 [==============================] - 84s 59ms/step - loss: 0.2243 - accuracy: 0.9291 - val_loss: 0.8396 - val_accuracy: 0.7980\n",
      "Epoch 124/200\n",
      "1407/1407 [==============================] - 83s 59ms/step - loss: 0.2263 - accuracy: 0.9284 - val_loss: 1.0784 - val_accuracy: 0.7864\n",
      "Epoch 125/200\n",
      "1407/1407 [==============================] - 84s 59ms/step - loss: 0.2199 - accuracy: 0.9303 - val_loss: 0.8510 - val_accuracy: 0.7998\n",
      "Epoch 126/200\n",
      "1407/1407 [==============================] - 84s 59ms/step - loss: 0.2239 - accuracy: 0.9290 - val_loss: 0.9646 - val_accuracy: 0.7920\n",
      "Epoch 127/200\n",
      "1407/1407 [==============================] - 83s 59ms/step - loss: 0.2175 - accuracy: 0.9308 - val_loss: 0.9466 - val_accuracy: 0.7984\n",
      "Epoch 128/200\n",
      "1407/1407 [==============================] - 83s 59ms/step - loss: 0.2154 - accuracy: 0.9314 - val_loss: 0.8713 - val_accuracy: 0.8018\n",
      "Epoch 129/200\n",
      "1407/1407 [==============================] - 91s 64ms/step - loss: 0.2153 - accuracy: 0.9303 - val_loss: 0.8815 - val_accuracy: 0.8000\n",
      "Epoch 130/200\n",
      "1407/1407 [==============================] - 85s 61ms/step - loss: 0.2142 - accuracy: 0.9318 - val_loss: 0.9301 - val_accuracy: 0.7946\n",
      "Epoch 131/200\n",
      "1407/1407 [==============================] - 87s 62ms/step - loss: 0.2160 - accuracy: 0.9305 - val_loss: 0.8865 - val_accuracy: 0.8064\n",
      "Epoch 132/200\n",
      "1407/1407 [==============================] - 87s 62ms/step - loss: 0.2202 - accuracy: 0.9302 - val_loss: 0.9303 - val_accuracy: 0.8096\n",
      "Epoch 133/200\n",
      "1407/1407 [==============================] - 85s 61ms/step - loss: 0.2157 - accuracy: 0.9318 - val_loss: 0.8479 - val_accuracy: 0.7986\n",
      "Epoch 134/200\n",
      "1407/1407 [==============================] - 88s 62ms/step - loss: 0.2182 - accuracy: 0.9310 - val_loss: 0.8433 - val_accuracy: 0.7882\n",
      "Epoch 135/200\n",
      " 883/1407 [=================>............] - ETA: 31s - loss: 0.2125 - accuracy: 0.9325"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(inp, out) \u001b[38;5;66;03m# Укажем слой входа и слой выхода\u001b[39;00m\n\u001b[0;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 24\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m          \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kernel_size = 4 # размер ядра в свертывающих слоях\n",
    "\n",
    "inp = Input(shape=(depth, height, width))\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "conv_1 = Convolution2D(conv_depth_1, (kernel_size, kernel_size), padding='same', activation='relu')(inp)\n",
    "conv_2 = Convolution2D(conv_depth_1, (kernel_size, kernel_size), padding='same', activation='relu')(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size), padding='same')(conv_2)\n",
    "drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
    "conv_3 = Convolution2D(conv_depth_2, (kernel_size, kernel_size), padding='same', activation='relu')(drop_1)\n",
    "conv_4 = Convolution2D(conv_depth_2, (kernel_size, kernel_size), padding='same', activation='relu')(conv_3)\n",
    "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size), padding='same')(conv_4)\n",
    "drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "# Now flatten to 1D, apply FC -> ReLU (with dropout) -> softmax\n",
    "flat = Flatten()(drop_2) # Трансформируем в одномерный вектор\n",
    "hidden = Dense(hidden_size, activation='relu')(flat)\n",
    "drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "out = Dense(num_classes, activation='softmax')(drop_3)\n",
    "\n",
    "model = Model(inp, out) # Укажем слой входа и слой выхода\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "          verbose=1, validation_split=0.1) # Оставляем 10 процентов для тестирования\n",
    "\n",
    "model.evaluate(X_test, Y_test, verbose=1) # Оценим обученную модель на тестовых данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309506e0",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "\n",
    "В результате выполнения лабораторной работы можно сделать вывод о том, что "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0b768e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
