{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9208651",
   "metadata": {},
   "source": [
    "# Лабораторная работа 6\n",
    "\n",
    "   по теме\n",
    "                 \n",
    "   **Прогноз успеха фильмов по обзорам**\n",
    "   \n",
    "   ****\n",
    "\n",
    "   Выполнил студент\n",
    "\n",
    "   Группы БСТ1801\n",
    "\n",
    "   Харатишвили Заза"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2de072ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9a4e0862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем датасет\n",
    "from keras.datasets import imdb\n",
    "(training_data, training_targets), (testing_data,testing_targets) = imdb.load_data(num_words=10000)\n",
    "# Обьединяем данные в доль одной оси\n",
    "data = np.concatenate((training_data, testing_data), axis=0)\n",
    "targets = np.concatenate((training_targets, testing_targets),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "92cc240b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Категории: [0 1]\n",
      "Количество уникальных слов: 9998\n",
      "Средний размер обзора: 234.75892\n",
      "Стандартное отклонение: 173\n"
     ]
    }
   ],
   "source": [
    "print(\"Категории:\", np.unique(targets)) # Положительный или отрицательный обзоры\n",
    "print(\"Количество уникальных слов:\", len(np.unique(np.hstack(data))))\n",
    "length = [len(i) for i in data]\n",
    "print(\"Средний размер обзора:\", np.mean(length))\n",
    "print(\"Стандартное отклонение:\", round(np.std(length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "32ad90a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Номер: 1\n",
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим на первый обзор из датасета\n",
    "print(\"Номер:\", targets[0])\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5b029914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert # is an amazing actor and now the same being director # father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for # and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also # to the two little boy's that played the # of norman and paul they were just brilliant children are often left out of the # list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
     ]
    }
   ],
   "source": [
    "# Преобразуем индексы в слова\n",
    "index = imdb.get_word_index()\n",
    "reverse_index = dict([(value, key) for (key, value) in index.items()])\n",
    "decoded = \" \".join( [reverse_index.get(i - 3, \"#\") for i in data[0]] ) # Заменим неизвестные слова на #\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "29a184bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([50000 10000], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Подготовим данные\n",
    "# Заполним нулями каждый обзор, чтобы размер был 10000 чисел\n",
    "# Это необходимо, потому что каждый элемент входных данных должен иметь одинакоый размер\n",
    "\n",
    "def vectorize(sequences, dimension = 10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1\n",
    "    return results\n",
    "\n",
    "data = vectorize(data)\n",
    "print(tf.shape(data))\n",
    "\n",
    "targets = np.array(targets).astype(\"float32\") # Приведем к типу float32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0d2973b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([10000 10000], shape=(2,), dtype=int32)\n",
      "tf.Tensor([10000], shape=(1,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Разделим датасет на обучающий и тестировочный наборы. Обучающий 40 000 обзоров, тестовый — 10 000.\n",
    "test_x = data[:10000]\n",
    "test_y = targets[:10000]\n",
    "train_x = data[10000:]\n",
    "train_y = targets[10000:]\n",
    "\n",
    "print(tf.shape(test_x))\n",
    "print(tf.shape(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "b1a62ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_44 (Dense)            (None, 50)                500050    \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 505,201\n",
      "Trainable params: 505,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.3221 - acc: 0.8660 - val_loss: 0.2662 - val_acc: 0.8905\n",
      "Epoch 2/2\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.2011 - acc: 0.9215 - val_loss: 0.2718 - val_acc: 0.8918\n"
     ]
    }
   ],
   "source": [
    "# Создадим и обучим модель\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(50, activation = \"relu\", input_shape=(10000, )))\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(layers.Dense(50, activation = \"relu\"))\n",
    "model.add(layers.Dropout(0.2, noise_shape=None, seed=None))\n",
    "model.add(layers.Dense(50, activation = \"relu\"))\n",
    "model.add(layers.Dense(1, activation = \"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "# Компилируем модель\n",
    "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"acc\"])\n",
    "\n",
    "results = model.fit(train_x, train_y, epochs= 2, batch_size = 32, validation_data = (test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "048096a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность обучения: 0.8911499977111816\n"
     ]
    }
   ],
   "source": [
    "# Проведем оценку работы модели\n",
    "print(\"Точность обучения:\", np.mean(results.history[\"val_acc\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdc5c15",
   "metadata": {},
   "source": [
    "Напишем функцию иморта пользовательского текстового файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c9434b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e92c44bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_words(input):\n",
    "    # lowercase everything to standardize it\n",
    "    input = input.lower()\n",
    "\n",
    "    # instantiate the tokenizer\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(input)\n",
    "\n",
    "    # if the created token isn't in the stop words, make it part of \"filtered\"\n",
    "    # filtered = filter(lambda token: token not in stopwords.words('english'), tokens)\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "8a20a40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video games as perhaps the most popular form of entertainment nowadays is currently suffering from the same problem surprisingly in the times when you needed to insert a magnetic tape cassette into your zx spectrum to play anything games could offer more thrill and fun than today not because games were better but mostly because the ideas they implemented were still new\n",
      "Total number of characters: 371\n",
      "Total vocab: 24\n"
     ]
    }
   ],
   "source": [
    "file = open(\"text.txt\",'r').read()\n",
    "\n",
    "processed_inputs = tokenize_words(file)\n",
    "processed_inputs = processed_inputs.replace(\"ђ\", \"\")\n",
    "processed_inputs = processed_inputs.replace(\"њ\", \"\")\n",
    "processed_inputs = processed_inputs.replace(\"ќ\", \"\")\n",
    "processed_inputs = processed_inputs.replace(\"в\", \"\")\n",
    "\n",
    "chars = sorted(list(set(processed_inputs)))\n",
    "char_to_num = dict((c, i) for i, c in enumerate(chars))\n",
    "\n",
    "print(processed_inputs)\n",
    "\n",
    "input_len = len(processed_inputs)\n",
    "vocab_len = len(chars)\n",
    "print (\"Total number of characters:\", input_len)\n",
    "print (\"Total vocab:\", vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "7bbd19d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns: 370\n",
      "tf.Tensor([  370 10000], shape=(2,), dtype=int32)\n",
      "tf.Tensor([370   1], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "seq_length = 1\n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "# loop through inputs, start at the beginning and go until we hit\n",
    "# the final character we can create a sequence out of\n",
    "for i in range(0, input_len - seq_length, 1):\n",
    "    # Define input and output sequences\n",
    "    # Input is the current character plus desired sequence length\n",
    "    in_seq = processed_inputs[i:i + seq_length]\n",
    "\n",
    "    # Out sequence is the initial character plus total sequence length\n",
    "    out_seq = processed_inputs[i + seq_length]\n",
    "\n",
    "    # We now convert list of characters to integers based on\n",
    "    # previously and add the values to our lists\n",
    "    x_data.append([char_to_num[char] for char in in_seq])\n",
    "    y_data.append(char_to_num[out_seq])\n",
    "\n",
    "n_patterns = len(x_data)\n",
    "print (\"Total Patterns:\", n_patterns)\n",
    "\n",
    "X = np.reshape(x_data, (n_patterns, seq_length))\n",
    "X = X/float(vocab_len)\n",
    "\n",
    "def vectorize(sequences, dimension = 10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1\n",
    "    return results\n",
    "y_data = vectorize(y_data)\n",
    "\n",
    "print(tf.shape(y_data))\n",
    "print(tf.shape(X))\n",
    "\n",
    "y_data = np.array(y_data).astype(\"float32\") # Приведем к типу float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "9f3f3a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 0.685989499092102\n"
     ]
    }
   ],
   "source": [
    "data_loss, data_accuracy = model.evaluate(y_data, X, verbose=0)\n",
    "print('test acc:', data_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f8e04d",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "\n",
    "В результате выполнения лабораторной работы можно сделать вывод о том, что "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29168108",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d7efff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
