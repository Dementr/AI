{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9b00585",
   "metadata": {},
   "source": [
    "# Лабораторная работа 4\n",
    "\n",
    "   по теме\n",
    "                 \n",
    "   **Распознавание рукописных символов**\n",
    "   \n",
    "   ****\n",
    "\n",
    "   Выполнил студент\n",
    "\n",
    "   Группы БСТ1801\n",
    "\n",
    "   Харатишвили Заза"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a6413b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Импорт бибилиотек и методов\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b79e1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Получение данных\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels),(test_images, test_labels) = mnist.load_data()\n",
    "#train - тренировочные наборы для обучения\n",
    "#test - контрольный набор для тестирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "76437de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "#Сравнение текстового изображения с его меткой для проверки корректности\n",
    "plt.imshow(train_images[0],cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "43765928",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Нормализуем входные данные путем преобразования изоображения в массивы в бинарный интервал [0,1] из [0;255]\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb17d26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "#Закодируем метки категорий - Переведем изображения в унитарный код\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "print (test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0aae0776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 1s 875us/step - loss: 0.3026 - accuracy: 0.9147\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 0s 868us/step - loss: 0.1320 - accuracy: 0.9618\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 0s 860us/step - loss: 0.0915 - accuracy: 0.9731\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 0s 841us/step - loss: 0.0686 - accuracy: 0.9803\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 0s 846us/step - loss: 0.0538 - accuracy: 0.9840\n",
      "Test data loss: 0.07652094215154648\n",
      "Test data accuracy: 0.9768999814987183\n",
      "Train data loss: 0.039634909480810165\n",
      "Train data accuracy: 0.989883303642273\n"
     ]
    }
   ],
   "source": [
    "#Задаем базовую архитектуру сети\n",
    "model = Sequential()\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#Настраиваем параметры сети\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Начинаем обучение сети\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)\n",
    "\n",
    "#Проверяем как модель распознает тестовый набор\n",
    "test_loss, test_accuracy = model.evaluate(\n",
    "    test_images, test_labels, verbose=0)\n",
    "print('Test data loss:', test_loss)\n",
    "print('Test data accuracy:', test_accuracy)\n",
    "#Проверяем как модель распознает контрольный набор\n",
    "train_loss, train_accuracy = model.evaluate(\n",
    "    train_images, train_labels, verbose=0)\n",
    "print('Train data loss:', train_loss)\n",
    "print('Train data accuracy:', train_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7ebc65",
   "metadata": {},
   "source": [
    "Найдем архитектуру сети, точность классификации которой будет не менее 95%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "427f247e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Получение данных\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(new_train_images, new_train_labels),(new_test_images, new_test_labels) = mnist.load_data()\n",
    "#train - тренировочные наборы для обучения\n",
    "#test - контрольный набор для тестирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "21548931",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Нормализуем входные данные путем преобразования изоображения в массивы в бинарный интервал [0,1] из [0;255]\n",
    "new_train_images = new_train_images / 255.0\n",
    "new_test_images = new_test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7951dec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "#Закодируем метки категорий - конструирование вектора с нулевыми элементами со значением 1 в\n",
    "# элементе, индекс которого соответствует индексу метки\n",
    "#Конвертируем из 1 измерения в 10 измерений\n",
    "new_train_labels = to_categorical(new_train_labels)\n",
    "new_test_labels = to_categorical(new_test_labels)\n",
    "print (test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "38538e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2196 - accuracy: 0.9348\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0972 - accuracy: 0.9700\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0707 - accuracy: 0.9781\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0537 - accuracy: 0.9825\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0436 - accuracy: 0.9857\n",
      "Test data loss: 0.06952299177646637\n",
      "Test data accuracy: 0.9796000123023987\n",
      "Train data loss: 0.02395610138773918\n",
      "Train data accuracy: 0.9923666715621948\n"
     ]
    }
   ],
   "source": [
    "## Создание массивов для вывода метрик\n",
    "all_train_images = []\n",
    "all_mse_histories = []\n",
    "\n",
    "\n",
    "#Задаем базовую архитектуру сети\n",
    "model = Sequential()\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2)) #Случайно отключает нейроны в фазе обучения\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#Настраиваем параметры сети\n",
    "model.compile(optimizer='Adam',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Начинаем обучение сети\n",
    "history = model.fit(new_train_images, new_train_labels, epochs=5, batch_size=32)\n",
    "\n",
    "#Проверяем как модель распознает тестовый набор\n",
    "test_loss, test_accuracy = model.evaluate(\n",
    "    new_test_images, new_test_labels, verbose=0)\n",
    "print('Test data loss:', test_loss)\n",
    "print('Test data accuracy:', test_accuracy)\n",
    "#Проверяем как модель распознает контрольный набор\n",
    "train_loss, train_accuracy = model.evaluate(\n",
    "    new_train_images, new_train_labels, verbose=0)\n",
    "print('Train data loss:', train_loss)\n",
    "print('Train data accuracy:', train_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0c18e9",
   "metadata": {},
   "source": [
    "Напишем функцию, которая позволит загружать пользовательское изображение не из датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a7e96dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Импорт бибилиотек\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "72b3f227",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Зададим размеры изображения и получим произведения элементов для reshape\n",
    "img_size = (28, 28)\n",
    "img_size_flat = np.prod(img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "381e4b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим данные\n",
    "(train_images, train_labels),(test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Переведем данные в формат с плавающей запятой, поскольку они являютстя целыми числами,\n",
    "#изменим форму матрицы, чтобы она была в одну строку (reshape) и проведем нормализацию, поделив на 255\n",
    "train_images = train_images.reshape(-1, img_size_flat).astype('float32') / 255\n",
    "test_images = test_images.reshape(-1, img_size_flat).astype('float32') / 255\n",
    "\n",
    "# Переведем изображения в унитарный код\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b6628ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.3065 - accuracy: 0.9151 - val_loss: 0.1617 - val_accuracy: 0.9524\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.1324 - accuracy: 0.9613 - val_loss: 0.1106 - val_accuracy: 0.9670\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 0s 958us/step - loss: 0.0893 - accuracy: 0.9742 - val_loss: 0.0892 - val_accuracy: 0.9726\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 0s 946us/step - loss: 0.0657 - accuracy: 0.9811 - val_loss: 0.0745 - val_accuracy: 0.9774\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 0s 936us/step - loss: 0.0502 - accuracy: 0.9855 - val_loss: 0.0717 - val_accuracy: 0.9779\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 0s 945us/step - loss: 0.0389 - accuracy: 0.9891 - val_loss: 0.0688 - val_accuracy: 0.9793\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 0s 960us/step - loss: 0.0311 - accuracy: 0.9913 - val_loss: 0.0674 - val_accuracy: 0.9794\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 0s 947us/step - loss: 0.0251 - accuracy: 0.9931 - val_loss: 0.0675 - val_accuracy: 0.9788\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 0s 1000us/step - loss: 0.0190 - accuracy: 0.9952 - val_loss: 0.0659 - val_accuracy: 0.9802\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 0s 980us/step - loss: 0.0150 - accuracy: 0.9963 - val_loss: 0.0669 - val_accuracy: 0.9787\n",
      "Test data loss: 0.06686843186616898\n",
      "Test data accuracy: 0.9786999821662903\n",
      "Train data loss: 0.010907994583249092\n",
      "Train data accuracy: 0.9981666803359985\n"
     ]
    }
   ],
   "source": [
    "#Задаем базовую архитектуру сети\n",
    "model = Sequential()\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#Настраиваем параметры сети\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Начинаем обучение сети\n",
    "model.fit(train_images, train_labels, epochs=10, batch_size=128, validation_data=(test_images, test_labels))\n",
    "\n",
    "#Проверяем как модель распознает тестовый набор\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels, verbose=0)\n",
    "print('Test data loss:', test_loss)\n",
    "print('Test data accuracy:', test_accuracy)\n",
    "#Проверяем как модель распознает контрольный набор\n",
    "train_loss, train_accuracy = model.evaluate(train_images, train_labels, verbose=0)\n",
    "print('Train data loss:', train_loss)\n",
    "print('Train data accuracy:', train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a9908ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция получения изображения и его преобразования для дальнейшей работы\n",
    "# url - ссылка на изображение\n",
    "# target_size - размер изображения, преобразуем до 28х28 пикселей\n",
    "# convert_to='L' - преобразование цвета изображения на оттенки серого\n",
    "def get_image(url, target_size=(img_size), convert_to='L'):\n",
    "    if url.lower().startswith('http'):\n",
    "        r = requests.get(url)\n",
    "        url = BytesIO(r.content)\n",
    "    img = (Image.open(url).convert(convert_to).resize(target_size))\n",
    "    return np.array(img).reshape(-1, np.prod(target_size))\n",
    "\n",
    "def predict_digit(img, model):\n",
    "    return model.predict(img).argmax() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f9126be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAANL0lEQVR4nO3df6jV933H8dcrmQWjjeiSXSSNS20CQYbTRkJgYZgESxYI2hBMJYyMCbfBJtQwaKULNDCGyTIXCCEFS0Pd6CzNrymmrHXSxOUf8SouamKbNCh6NUpmQiMmOON7f9yv5dbc8znXc77nfE98Px9wOed83+d7vm+++PL763zPxxEhAJe+y5puAEB/EHYgCcIOJEHYgSQIO5DEH/VzYbY59Q/0WER4ouldbdlt32n717bfsb2mm88C0Fvu9Dq77csl/UbSEklHJO2UtCIi3izMw5Yd6LFebNlvlvRORLwbEWck/VTS0i4+D0APdRP2ayQdHvf6SDXtD9getj1ie6SLZQHoUs9P0EXEeknrJXbjgSZ1s2UflXTtuNdfqqYBGEDdhH2npBtsf9n2FyR9Q9LmetoCULeOd+Mj4qzthyT9QtLlkp6LiP21dQagVh1feutoYRyzAz3Xky/VAPj8IOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IIm+/pQ0OjN37txi/b777mtZmz9/flfLPnDgQLG+adOmYn3Pnj1dLR/1YcsOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0nw67ID4JFHHinWH3zwwWL99ddfb1nbvLn8U/5nz54t1hcvXlysL1mypFjfuXNny9rDDz9cnPeTTz4p1jExfl0WSI6wA0kQdiAJwg4kQdiBJAg7kARhB5LgOnsfPProo8X68uXLi/UVK1YU6/v3NzdS9tDQULG+YcOGlrXXXnutOO/atWs76im7VtfZu/rxCtsHJX0k6VNJZyNiUTefB6B36vilmtsi4v0aPgdAD3HMDiTRbdhD0i9t77I9PNEbbA/bHrE90uWyAHSh2934WyNi1PafSNpq+0BEbB//hohYL2m9lPcEHTAIutqyR8Ro9XhC0suSbq6jKQD16zjstqfZ/uL555K+JmlfXY0BqFc3u/FDkl62ff5z/j0i/rOWrj5nVq9eXawvW7asWL/77ruL9UOHDl1kR/1z/PjxYv2JJ55oWVu1alXd7aCg47BHxLuS/rzGXgD0EJfegCQIO5AEYQeSIOxAEoQdSIIhm2uwffv2Yv35558v1kdHR+tsZ6DMmTOnZY2fiu4vtuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATX2Wuwe/fuplsYWHfccUfL2o4dO/rYCdiyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASDNmMrsybN69Yf+WVV1rWbrvttuK8Bw8e7KSl9FoN2cyWHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeS4H52FM2YMaNYf/bZZ4v1p59+umWN6+j91XbLbvs52yds7xs3bZbtrbbfrh5n9rZNAN2azG78jyXdecG0NZK2RcQNkrZVrwEMsLZhj4jtkk5eMHmppA3V8w2SltXbFoC6dXrMPhQRx6rn70kaavVG28OShjtcDoCadH2CLiKidINLRKyXtF7iRhigSZ1eejtue7YkVY8n6msJQC90GvbNkh6onj8gaVM97QDolbb3s9veKGmxpKskHZf0fUn/IelnkuZIOiRpeURceBJvos9iN77P7Alvbf69m266qVh/8skni/UtW7YU6+vWrSvWUb9W97O3PWaPiBUtSq1//R/AwOHrskAShB1IgrADSRB2IAnCDiTBLa41mDZtWrF+//33dzV/OzfeeGPL2i233FKcd/78+cX6gQMHivWjR48W61OnTm1Z+/jjj4vzol5s2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCYZsrsGVV15ZrK9cubJYv+KKK7pa/rlz5zqqSdKZM2e6WvaSJUuK9csua709ueeee4rznj59uqOesmPIZiA5wg4kQdiBJAg7kARhB5Ig7EAShB1Iguvs6KlXX321ZW3TpvJwA0899VTN3eTAdXYgOcIOJEHYgSQIO5AEYQeSIOxAEoQdSILr7OipRYsWtaxt3LixOO/tt99erB8+fLijni51HV9nt/2c7RO2942b9pjtUdt7qr+76mwWQP0msxv/Y0l3TjD9qYhYUP39vN62ANStbdgjYrukk33oBUAPdXOC7iHbb1S7+TNbvcn2sO0R2yNdLAtAlzoN+w8kfUXSAknHJK1r9caIWB8RiyKi9ZkaAD3XUdgj4nhEfBoR5yT9UNLN9bYFoG4dhd327HEvvy5pX6v3AhgMbcdnt71R0mJJV9k+Iun7khbbXiApJB2U9M3etYjPs5GR1qdq9u7dW5z3+uuvL9a5zn5x2oY9IlZMMPlHPegFQA/xdVkgCcIOJEHYgSQIO5AEYQeSaHs2HuiVU6dONd1CKmzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJrrOjp66++uqWtYULFxbnfeaZZ+puJzW27EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBNfZazA8PFysf/DBB8X61q1bi/UPP/zwYluqzZQpU4r1+fPnF+ula+Vbtmwpzrtr165iHReHLTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJOGI6N/C7P4trI/uvffeYn3VqlXF+owZM4r1I0eOFOujo6PFesnUqVOL9blz5xbr06dPL9ZfeOGFlrW1a9cW50VnIsITTW+7Zbd9re1f2X7T9n7b366mz7K91fbb1ePMupsGUJ/J7MaflfR3ETFP0i2SvmV7nqQ1krZFxA2StlWvAQyotmGPiGMRsbt6/pGktyRdI2mppA3V2zZIWtajHgHU4KK+G2/7OkkLJe2QNBQRx6rSe5KGWswzLKn85XEAPTfps/G2p0t6UdLqiPjd+FqMneWb8ORbRKyPiEURsairTgF0ZVJhtz1FY0H/SUS8VE0+bnt2VZ8t6URvWgRQh7aX3mxbY8fkJyNi9bjpT0r634h43PYaSbMi4jttPuuSvPTWrTlz5hTrCxYsKNbb3YZacu7cuWJ97969xfrRo0eL9dOnT190T+hOq0tvkzlm/wtJfy1pr+091bTvSXpc0s9sr5R0SNLyGvoE0CNtwx4Rr0ua8H8KSXfU2w6AXuHrskAShB1IgrADSRB2IAnCDiTBLa7AJabjW1wBXBoIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgibZht32t7V/ZftP2ftvfrqY/ZnvU9p7q767etwugU20HibA9W9LsiNht+4uSdklaprHx2E9FxD9PemEMEgH0XKtBIiYzPvsxSceq5x/ZfkvSNfW2B6DXLuqY3fZ1khZK2lFNesj2G7afsz2zxTzDtkdsj3TXKoBuTHqsN9vTJb0m6R8j4iXbQ5LelxSS/kFju/p/2+Yz2I0HeqzVbvykwm57iqQtkn4REf8yQf06SVsi4s/afA5hB3qs44EdbVvSjyS9NT7o1Ym7874uaV+3TQLoncmcjb9V0n9L2ivpXDX5e5JWSFqgsd34g5K+WZ3MK30WW3agx7raja8LYQd6j/HZgeQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSbT9wcmavS/p0LjXV1XTBtGg9jaofUn01qk6e/vTVoW+3s/+mYXbIxGxqLEGCga1t0HtS6K3TvWrN3bjgSQIO5BE02Ff3/DySwa1t0HtS6K3TvWlt0aP2QH0T9NbdgB9QtiBJBoJu+07bf/a9ju21zTRQyu2D9reWw1D3ej4dNUYeids7xs3bZbtrbbfrh4nHGOvod4GYhjvwjDjja67poc/7/sxu+3LJf1G0hJJRyTtlLQiIt7sayMt2D4oaVFENP4FDNt/KemUpH89P7SW7X+SdDIiHq/+o5wZEd8dkN4e00UO492j3loNM/43anDd1Tn8eSea2LLfLOmdiHg3Is5I+qmkpQ30MfAiYrukkxdMXippQ/V8g8b+sfRdi94GQkQci4jd1fOPJJ0fZrzRdVfoqy+aCPs1kg6Pe31EgzXee0j6pe1dtoebbmYCQ+OG2XpP0lCTzUyg7TDe/XTBMOMDs+46Gf68W5yg+6xbI+Krkv5K0req3dWBFGPHYIN07fQHkr6isTEAj0la12Qz1TDjL0paHRG/G19rct1N0Fdf1lsTYR+VdO2411+qpg2EiBitHk9Ielljhx2D5Pj5EXSrxxMN9/N7EXE8Ij6NiHOSfqgG1101zPiLkn4SES9VkxtfdxP11a/11kTYd0q6wfaXbX9B0jckbW6gj8+wPa06cSLb0yR9TYM3FPVmSQ9Uzx+QtKnBXv7AoAzj3WqYcTW87hof/jwi+v4n6S6NnZH/raS/b6KHFn3NlfQ/1d/+pnuTtFFju3X/p7FzGysl/bGkbZLelvRfkmYNUG//prGhvd/QWLBmN9TbrRrbRX9D0p7q766m112hr76sN74uCyTBCTogCcIOJEHYgSQIO5AEYQeSIOxAEoQdSOL/ARo0PtBOvjyDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Загрузим свою картинку и подадим ее на вход обученной модели\n",
    "img = get_image(r\"C:\\Users\\zazah\\sii\\lab4\\3.png\")\n",
    "#Узнаем предсказание для загруженного нами изображения в уже обученную модель\n",
    "predict = predict_digit(img, model)\n",
    "plt.imshow(img.reshape(img_size), cmap='gray')\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd04a2f",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "\n",
    "В результате выполнения лабораторной работы можно сделать вывод, что для задачи анализа изображения наиболее эффективен\n",
    "анализатор Adam, при использовании других оптимизаторов потери возрастают, а точность снижается. Также была реализована функция, которая выполняет загрузку пользовательского изображения с компьютера пользователя"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
