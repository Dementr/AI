{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9208651",
   "metadata": {},
   "source": [
    "# Лабораторная работа 6\n",
    "\n",
    "   по теме\n",
    "                 \n",
    "   **Прогноз успеха фильмов по обзорам**\n",
    "   \n",
    "   ****\n",
    "\n",
    "   Выполнил студент\n",
    "\n",
    "   Группы БСТ1801\n",
    "\n",
    "   Харатишвили Заза"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2de072ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9a4e0862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем датасет\n",
    "from keras.datasets import imdb\n",
    "(training_data, training_targets), (testing_data,testing_targets) = imdb.load_data(num_words=10000)\n",
    "# Обьединяем данные в доль одной оси\n",
    "data = np.concatenate((training_data, testing_data), axis=0)\n",
    "targets = np.concatenate((training_targets, testing_targets),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "92cc240b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Категории: [0 1]\n",
      "Количество уникальных слов: 9998\n",
      "Средний размер обзора: 234.75892\n",
      "Стандартное отклонение: 173\n"
     ]
    }
   ],
   "source": [
    "print(\"Категории:\", np.unique(targets)) # Положительный или отрицательный обзоры\n",
    "print(\"Количество уникальных слов:\", len(np.unique(np.hstack(data))))\n",
    "length = [len(i) for i in data]\n",
    "print(\"Средний размер обзора:\", np.mean(length))\n",
    "print(\"Стандартное отклонение:\", round(np.std(length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "32ad90a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Номер: 1\n",
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим на первый обзор из датасета\n",
    "print(\"Номер:\", targets[0])\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5b029914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert # is an amazing actor and now the same being director # father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for # and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also # to the two little boy's that played the # of norman and paul they were just brilliant children are often left out of the # list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
     ]
    }
   ],
   "source": [
    "# Преобразуем индексы в слова\n",
    "index = imdb.get_word_index()\n",
    "reverse_index = dict([(value, key) for (key, value) in index.items()])\n",
    "decoded = \" \".join( [reverse_index.get(i - 3, \"#\") for i in data[0]] ) # Заменим неизвестные слова на #\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "29a184bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовим данные\n",
    "# Заполним нулями каждый обзор, чтобы размер был 10000 чисел\n",
    "# Это необходимо, потому что каждый элемент входных данных должен иметь одинакоый размер\n",
    "\n",
    "def vectorize(sequences, dimension = 10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1\n",
    "    return results\n",
    "\n",
    "data = vectorize(data)\n",
    "\n",
    "targets = np.array(targets).astype(\"float32\") # Приведем к типу float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d2973b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделим датасет на обучающий и тестировочный наборы. Обучающий 40 000 обзоров, тестировочный — 10 000.\n",
    "test_x = data[:10000]\n",
    "test_y = targets[:10000]\n",
    "train_x = data[10000:]\n",
    "train_y = targets[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1a62ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 50)                500050    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 505,201\n",
      "Trainable params: 505,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.4199 - acc: 0.8063 - val_loss: 0.2685 - val_acc: 0.8891\n",
      "Epoch 2/2\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2161 - acc: 0.9161 - val_loss: 0.2638 - val_acc: 0.8954\n"
     ]
    }
   ],
   "source": [
    "# Создадим и обучим модель\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(50, activation = \"relu\", input_shape=(10000, )))\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(layers.Dense(50, activation = \"relu\"))\n",
    "model.add(layers.Dropout(0.2, noise_shape=None, seed=None))\n",
    "model.add(layers.Dense(50, activation = \"relu\"))\n",
    "model.add(layers.Dense(1, activation = \"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "# Компилируем модель\n",
    "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"acc\"])\n",
    "\n",
    "results = model.fit(train_x, train_y, epochs= 2, batch_size = 500, validation_data = (test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "048096a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность обучения: 0.8922500014305115\n"
     ]
    }
   ],
   "source": [
    "# Проведем оценку работы модели\n",
    "print(\"Точность обучения:\", np.mean(results.history[\"val_acc\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdc5c15",
   "metadata": {},
   "source": [
    "Напишем функцию иморта пользовательского текстового файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9434b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e92c44bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_words(input):\n",
    "    # lowercase everything to standardize it\n",
    "    input = input.lower()\n",
    "\n",
    "    # instantiate the tokenizer\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(input)\n",
    "\n",
    "    # if the created token isn't in the stop words, make it part of \"filtered\"\n",
    "    # filtered = filter(lambda token: token not in stopwords.words('english'), tokens)\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a20a40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "в  jawsв   still evokes warm memories in me this is why i was disappointed with the sequels they could never recreate the feeling of imminent danger lurking beneath the sea surface besides they were worse than the original in almost every aspect long story short i like movies about sharks i also like sharks in general but even more than that i admire prehistoric gigantic sharks megalodons so when i saw trailers of в  the meg в   i knew what i wanted to watch now before you proceed to reading this review let me make two tiny disclaimers first of all there are going to be minor spoilers ahead so if you are one of those people who hate the idea of knowing what they are going to see in a movie i recommend you to stop reading now secondly i liked the movie even though sometimes it feels cringely stupid okay now letв  s move on в  the megв   was filmed by jon turteltaub in 2018 and is based upon a novel by steve altenв  at least this is what wikipedia says i want to believe that the bookв  в  meg a novel of a deep terrorв  в  is much more consistent than the movie and matches the criteria of the sci fi genre the film however even though it is often related to в  sci fiв   and в  horror is actually a typical popcorn action movie with jason statham i have nothing against summer blockbusters i guess i was just hoping to see a sci fi horror movie about a huge sharkв  something like в  jaws в   anyways the movie tells about a team of scientists financed by an eccentric billionaire who discover that the mariana trench is much deeper than it was believed before what was considered to be its bottom turns out to be a dense layer of hydrogen sulfide forming a thermocline this layer covers a whole new ecosystem and to research it scientists send a submersible with a team of three people lori toshi and в  the wallв   i cannot recall this guy being named otherwise when they penetrate the thermocline they witness a rich variety of unique flora and fauna that has developed under the layer of hydrogen sulfide however soon after the discovery the submersible is attacked by a huge squidв  which in its turn gets attacked by a megalodon the submersible is heavily damaged lori is wounded and in order to save them dr minway zhangв  the head of the mana one station from which all the research is conductedв  decides to fetch an experienced lifesaver this lifesaver is jason statв  uh jonas taylor who had once faced a megalodon during a lifesaving operation with tragic consequences i will not get into further details regarding the movieв  s plot except cases when i need to illustrate one claim that i make or another for now let us focus on the movieв  s strong sides and gradually move to criticizing it в  the megв   is a distilled action movieв  and i would even say it could serve as a decent example of how action movies should be made the word в  actionв   obviously implies people running around and all things fluttering and going boom unfortunately hollywood producers and directors sometimes seem to be forget about this and we get to see such sluggish в  actionв   movies as в  terminator genisysв   sorry arnie but it sucked or в  transformers the last knight в   in this regard в  the megв   reminded me of в  mad max fury roadв   almost every minute of the movie is packed with events and a few calm episodes only serve as transitions between intense action one ordeal is changed by another and the flux of tough situations the main characters have to overcome never stops due to this в  the megв   is be watched in one breath there was no such moment when i would feel like the movie was boring or slow в  the megв   is packed with action up to the top i also enjoyed the visual aspect of the movie i watched it in an imax theater which is obviously the go to technology for such movies so i believe i experienced everything в  the megв   has to offer in terms of graphics and visuals mysterious underwater landscapes enormous beasts the hi tech futuristic mana one base the megalodonв  there is quite a lot to see in в  the meg в   scenes when the characters are surrounded with smaller sharks or when their submersibles get clenched in gigantic teeth are a breathtaking combination of beauty and thrill all the action scenes are filmed masterfully utilizing dynamic angles and perspective which helps convey drama and pumps adrenaline in the moments when it was needed add nice 3d effects and the imax effect of presence and you get a spectacular movie to watch my main rants about в  the megв   are related to the screenplay and the overall logic of actions first of all when loriв  s submersible she is taylorв  s ex wife by the way gets stuck deep under water dr zhang sends his people to seek for taylor in thailand they go find taylor take him to mana one he takes his time to get accustomedв  and what the submersible is still there like is the shark just waiting for taylor to arrive and save the day while the scientists are searching for taylor dr zhangв  s daughter suyin decides to dive in and rescue loriв  s crew herself the whole time taylor is travelling to mana one suyin is submerging she gets attacked by the same squid as loriв  s bathyscaphe taylor rushes for helpв  and reaches the bottom in just several minutes itв  s the mariana trench karl eleven kilometers how now the fact that lori is taylorв  s ex wife changes nothing in the plot it is the main argument for scientists to persuade taylor take the job and he acts all worried but after lori is saved taylor goes completely cold turkey about her paying much more attention to suyin scientists quickly figure out they have to deal with a megalodonв  but instead of approaching the matter with all due seriousness they just crack jokes and do nothing to prepare to fight with the monster they know the shark is 75 feet longв  and what they just sail off on a small boat to kill her they use a super tough ultra modern shark cageв  and what they just dunk it underwater using a thin line and a flimsy crane their friends die in the sharkв  s mawв  and what they just move on right away the amount of inconsistencies logical flaws and plot holes in в  the megв   is amazing usually people start noticing flaws when watching a movie for the second or even third time in the case of в  the meg в   you can see the flaws immediately they just jump at you out of nowhere yelling в  behold i am a huge hole in the logic of this movie в   oh and for a movie dedicated to a huge prehistoric shark i would really love to see more of it there were several amazing moments with the megalodon showing off its jaws or boasting of its enormous size but i still feel like there could be more other than this there is not so much to talk about the soundtrack and music are okay although not memorable actors do their jobs jason statham saves everyone multiple times women adore jason statham guys who are not jason statham either die heroically or stay in the background if you are looking for a nice action movie for a summer night в  the megв   is something you might want to consider\n",
      "Total number of characters: 7077\n",
      "Total vocab: 35\n"
     ]
    }
   ],
   "source": [
    "file = open(\"text.txt\",'r').read()\n",
    "\n",
    "processed_inputs = tokenize_words(file)\n",
    "processed_inputs = processed_inputs.replace(\"ђ\", \" \")\n",
    "# processed_inputs = processed_inputs.replace(\"њ\", \" \")\n",
    "# processed_inputs = processed_inputs.replace(\"ќ\", \" \")\n",
    "\n",
    "chars = sorted(list(set(processed_inputs)))\n",
    "char_to_num = dict((c, i) for i, c in enumerate(chars))\n",
    "\n",
    "print(processed_inputs)\n",
    "\n",
    "input_len = len(processed_inputs)\n",
    "vocab_len = len(chars)\n",
    "print (\"Total number of characters:\", input_len)\n",
    "print (\"Total vocab:\", vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7bbd19d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns: 6977\n",
      "Epoch 1/2\n",
      "75/80 [===========================>..] - ETA: 0s - loss: 0.1024 - acc: 0.9658"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\zazah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1525, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\zazah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1514, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\zazah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1507, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\Users\\zazah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1471, in test_step\n        y_pred = self(x, training=False)\n    File \"C:\\Users\\zazah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\zazah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 10000), found shape=(None, 100, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [69]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m y_data \u001b[38;5;241m=\u001b[39m vectorize(y_data)\n\u001b[0;32m     34\u001b[0m y_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y_data)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# Приведем к типу float32\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m   1148\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\zazah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1525, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\zazah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1514, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\zazah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1507, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\Users\\zazah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1471, in test_step\n        y_pred = self(x, training=False)\n    File \"C:\\Users\\zazah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\zazah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 10000), found shape=(None, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "# loop through inputs, start at the beginning and go until we hit\n",
    "# the final character we can create a sequence out of\n",
    "for i in range(0, input_len - seq_length, 1):\n",
    "    # Define input and output sequences\n",
    "    # Input is the current character plus desired sequence length\n",
    "    in_seq = processed_inputs[i:i + seq_length]\n",
    "\n",
    "    # Out sequence is the initial character plus total sequence length\n",
    "    out_seq = processed_inputs[i + seq_length]\n",
    "\n",
    "    # We now convert list of characters to integers based on\n",
    "    # previously and add the values to our lists\n",
    "    x_data.append([char_to_num[char] for char in in_seq])\n",
    "    y_data.append(char_to_num[out_seq])\n",
    "\n",
    "n_patterns = len(x_data)\n",
    "print (\"Total Patterns:\", n_patterns)\n",
    "\n",
    "X = np.reshape(x_data, (n_patterns, seq_length, 1))\n",
    "X = X/float(vocab_len)\n",
    "\n",
    "def vectorize(sequences, dimension = 10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1\n",
    "    return results\n",
    "\n",
    "y_data = vectorize(y_data)\n",
    "\n",
    "y_data = np.array(y_data).astype(\"float32\") # Приведем к типу float32\n",
    "\n",
    "results = model.fit(train_x, train_y, epochs= 2, batch_size = 500, validation_data = (X, y_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f8e04d",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "\n",
    "В результате выполнения лабораторной работы можно сделать вывод о том, что "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29168108",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d7efff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
