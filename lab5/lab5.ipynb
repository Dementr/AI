{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e305852c",
   "metadata": {},
   "source": [
    "# Лабораторная работа 5\n",
    "\n",
    "   по теме\n",
    "                 \n",
    "   **Распознавание объектов на фотографиях**\n",
    "   \n",
    "   ****\n",
    "\n",
    "   Выполнил студент\n",
    "\n",
    "   Группы БСТ1801\n",
    "\n",
    "   Харатишвили Заза"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3825c28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Импорты\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0defa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 # на каждой итерации одновременно обрабатываем 32 обучающих образца\n",
    "num_epochs = 100 # количество итераций\n",
    "kernel_size = 3 # размер ядра в свертывающих слоях\n",
    "pool_size = 2 # размер подвыборки в слоях подвыборки\n",
    "conv_depth_1 = 32 # количество ядер в свертывающих слоях\n",
    "conv_depth_2 = 64 # увеличиваем в два раза после слоя подвыборки \n",
    "drop_prob_1 = 0.25 # убираем нейроны после слоя подвыборки с вероятностью 0.25\n",
    "drop_prob_2 = 0.5 # убираем нейроны после полносвязного слоя с вероятностью 0.5\n",
    "hidden_size = 512 # количество нейронов в полносвязном слое"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "314a4dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data() # получаем данные CIFAR-10 \n",
    "#96x96,255\n",
    "# 50000 данных для обучения, 10000 для тестирования, 10 классов картинок\n",
    "num_train, depth, height, width = X_train.shape\n",
    "num_test = X_test.shape[0]\n",
    "num_classes = np.unique(y_train).shape[0]\n",
    "\n",
    "# Приведем к виду с плавающей точкой\n",
    "X_train = X_train.astype('float32') \n",
    "X_test = X_test.astype('float32')\n",
    "# Преобразуем интетнсивность пикселей до [0 ,1]\n",
    "X_train /= np.max(X_train)\n",
    "X_test /= np.max(X_train) #делим на обучающее, тк нельзя показывать алгоритмам тестовые данные до окончания \n",
    "# процесса обучения\n",
    "\n",
    "# переводим в унитарный код\n",
    "Y_train = to_categorical(y_train, num_classes)\n",
    "Y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dc1c671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 53s 37ms/step - loss: 1.5683 - accuracy: 0.4249 - val_loss: 1.1585 - val_accuracy: 0.5794\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 1.1393 - accuracy: 0.5930 - val_loss: 0.9520 - val_accuracy: 0.6650\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.9900 - accuracy: 0.6473 - val_loss: 0.8460 - val_accuracy: 0.7052\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.8979 - accuracy: 0.6816 - val_loss: 0.8068 - val_accuracy: 0.7170\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.8264 - accuracy: 0.7075 - val_loss: 0.7663 - val_accuracy: 0.7362\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.7673 - accuracy: 0.7287 - val_loss: 0.7339 - val_accuracy: 0.7498\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.7225 - accuracy: 0.7439 - val_loss: 0.7538 - val_accuracy: 0.7374\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.6822 - accuracy: 0.7582 - val_loss: 0.7265 - val_accuracy: 0.7552\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.6465 - accuracy: 0.7713 - val_loss: 0.6758 - val_accuracy: 0.7696\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.6172 - accuracy: 0.7817 - val_loss: 0.6597 - val_accuracy: 0.7688\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.5984 - accuracy: 0.7868 - val_loss: 0.6618 - val_accuracy: 0.7764\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.5622 - accuracy: 0.8017 - val_loss: 0.6614 - val_accuracy: 0.7800\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.5349 - accuracy: 0.8110 - val_loss: 0.6740 - val_accuracy: 0.7738\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.5205 - accuracy: 0.8149 - val_loss: 0.6745 - val_accuracy: 0.7770\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 53s 37ms/step - loss: 0.5076 - accuracy: 0.8224 - val_loss: 0.6696 - val_accuracy: 0.7850\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.4883 - accuracy: 0.8278 - val_loss: 0.6617 - val_accuracy: 0.7872\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.4793 - accuracy: 0.8306 - val_loss: 0.7031 - val_accuracy: 0.7700\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 53s 37ms/step - loss: 0.4659 - accuracy: 0.8358 - val_loss: 0.6663 - val_accuracy: 0.7880\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 53s 38ms/step - loss: 0.4432 - accuracy: 0.8430 - val_loss: 0.6873 - val_accuracy: 0.7802\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.4442 - accuracy: 0.8424 - val_loss: 0.6695 - val_accuracy: 0.7860\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.4284 - accuracy: 0.8477 - val_loss: 0.6988 - val_accuracy: 0.7858\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.4231 - accuracy: 0.8495 - val_loss: 0.7029 - val_accuracy: 0.7864\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.4148 - accuracy: 0.8550 - val_loss: 0.6852 - val_accuracy: 0.7868\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 53s 37ms/step - loss: 0.3955 - accuracy: 0.8601 - val_loss: 0.6753 - val_accuracy: 0.7946\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.3930 - accuracy: 0.8596 - val_loss: 0.6924 - val_accuracy: 0.7852\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.3866 - accuracy: 0.8650 - val_loss: 0.6642 - val_accuracy: 0.7956\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.3837 - accuracy: 0.8647 - val_loss: 0.6689 - val_accuracy: 0.7874\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.3709 - accuracy: 0.8714 - val_loss: 0.6673 - val_accuracy: 0.7932\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.3677 - accuracy: 0.8697 - val_loss: 0.6718 - val_accuracy: 0.7952\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 51s 37ms/step - loss: 0.3569 - accuracy: 0.8751 - val_loss: 0.7499 - val_accuracy: 0.7882\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.3597 - accuracy: 0.8762 - val_loss: 0.7081 - val_accuracy: 0.7866\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 51s 37ms/step - loss: 0.3540 - accuracy: 0.8770 - val_loss: 0.7243 - val_accuracy: 0.7862\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 51s 37ms/step - loss: 0.3525 - accuracy: 0.8788 - val_loss: 0.7022 - val_accuracy: 0.7958\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 51s 37ms/step - loss: 0.3482 - accuracy: 0.8790 - val_loss: 0.7153 - val_accuracy: 0.7880\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.3394 - accuracy: 0.8808 - val_loss: 0.7151 - val_accuracy: 0.7906\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.3352 - accuracy: 0.8849 - val_loss: 0.7258 - val_accuracy: 0.7938\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.3298 - accuracy: 0.8850 - val_loss: 0.7463 - val_accuracy: 0.7916\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.3311 - accuracy: 0.8852 - val_loss: 0.7953 - val_accuracy: 0.7890\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.3258 - accuracy: 0.8881 - val_loss: 0.7223 - val_accuracy: 0.7908\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.3207 - accuracy: 0.8885 - val_loss: 0.7690 - val_accuracy: 0.7874\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.3245 - accuracy: 0.8888 - val_loss: 0.7209 - val_accuracy: 0.7854\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.3206 - accuracy: 0.8904 - val_loss: 0.7428 - val_accuracy: 0.7992\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.3158 - accuracy: 0.8929 - val_loss: 0.7019 - val_accuracy: 0.7952\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.3120 - accuracy: 0.8947 - val_loss: 0.6979 - val_accuracy: 0.7970\n",
      "Epoch 45/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.3108 - accuracy: 0.8930 - val_loss: 0.7460 - val_accuracy: 0.7994\n",
      "Epoch 46/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.3055 - accuracy: 0.8954 - val_loss: 0.7479 - val_accuracy: 0.7858\n",
      "Epoch 47/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.3047 - accuracy: 0.8978 - val_loss: 0.7160 - val_accuracy: 0.8004\n",
      "Epoch 48/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2980 - accuracy: 0.8989 - val_loss: 0.7659 - val_accuracy: 0.7956\n",
      "Epoch 49/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.3023 - accuracy: 0.8957 - val_loss: 0.7492 - val_accuracy: 0.7930\n",
      "Epoch 50/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2967 - accuracy: 0.8987 - val_loss: 0.7470 - val_accuracy: 0.7972\n",
      "Epoch 51/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.3016 - accuracy: 0.8993 - val_loss: 0.7630 - val_accuracy: 0.7960\n",
      "Epoch 52/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2947 - accuracy: 0.8999 - val_loss: 0.7886 - val_accuracy: 0.7934\n",
      "Epoch 53/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2924 - accuracy: 0.9017 - val_loss: 0.7213 - val_accuracy: 0.7934\n",
      "Epoch 54/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2905 - accuracy: 0.9011 - val_loss: 0.7623 - val_accuracy: 0.7932\n",
      "Epoch 55/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2899 - accuracy: 0.9016 - val_loss: 0.7867 - val_accuracy: 0.7904\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2872 - accuracy: 0.9011 - val_loss: 0.7482 - val_accuracy: 0.8000\n",
      "Epoch 57/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2807 - accuracy: 0.9060 - val_loss: 0.7556 - val_accuracy: 0.7980\n",
      "Epoch 58/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2832 - accuracy: 0.9051 - val_loss: 0.8149 - val_accuracy: 0.7904\n",
      "Epoch 59/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2869 - accuracy: 0.9027 - val_loss: 0.8199 - val_accuracy: 0.7878\n",
      "Epoch 60/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2808 - accuracy: 0.9054 - val_loss: 0.7630 - val_accuracy: 0.7932\n",
      "Epoch 61/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2770 - accuracy: 0.9068 - val_loss: 0.8016 - val_accuracy: 0.7778\n",
      "Epoch 62/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2761 - accuracy: 0.9060 - val_loss: 0.8043 - val_accuracy: 0.7936\n",
      "Epoch 63/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2746 - accuracy: 0.9077 - val_loss: 0.8075 - val_accuracy: 0.7910\n",
      "Epoch 64/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2767 - accuracy: 0.9067 - val_loss: 0.7681 - val_accuracy: 0.7910\n",
      "Epoch 65/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2753 - accuracy: 0.9069 - val_loss: 0.7827 - val_accuracy: 0.7966\n",
      "Epoch 66/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2758 - accuracy: 0.9072 - val_loss: 0.7877 - val_accuracy: 0.7964\n",
      "Epoch 67/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2662 - accuracy: 0.9102 - val_loss: 0.7552 - val_accuracy: 0.8054\n",
      "Epoch 68/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2723 - accuracy: 0.9077 - val_loss: 0.7444 - val_accuracy: 0.7958\n",
      "Epoch 69/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2694 - accuracy: 0.9103 - val_loss: 0.7633 - val_accuracy: 0.7982\n",
      "Epoch 70/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2672 - accuracy: 0.9108 - val_loss: 0.7593 - val_accuracy: 0.8046\n",
      "Epoch 71/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2698 - accuracy: 0.9101 - val_loss: 0.7648 - val_accuracy: 0.8002\n",
      "Epoch 72/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2646 - accuracy: 0.9116 - val_loss: 0.7497 - val_accuracy: 0.7986\n",
      "Epoch 73/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2703 - accuracy: 0.9088 - val_loss: 0.7728 - val_accuracy: 0.8030\n",
      "Epoch 74/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2574 - accuracy: 0.9132 - val_loss: 0.8038 - val_accuracy: 0.7918\n",
      "Epoch 75/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2640 - accuracy: 0.9128 - val_loss: 0.7580 - val_accuracy: 0.8044\n",
      "Epoch 76/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2560 - accuracy: 0.9157 - val_loss: 0.7966 - val_accuracy: 0.7982\n",
      "Epoch 77/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2584 - accuracy: 0.9150 - val_loss: 0.8106 - val_accuracy: 0.7958\n",
      "Epoch 78/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2629 - accuracy: 0.9123 - val_loss: 0.7922 - val_accuracy: 0.7978\n",
      "Epoch 79/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2547 - accuracy: 0.9151 - val_loss: 0.7881 - val_accuracy: 0.8050\n",
      "Epoch 80/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2561 - accuracy: 0.9149 - val_loss: 0.8066 - val_accuracy: 0.7976\n",
      "Epoch 81/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2586 - accuracy: 0.9130 - val_loss: 0.8588 - val_accuracy: 0.7982\n",
      "Epoch 82/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2558 - accuracy: 0.9147 - val_loss: 0.8372 - val_accuracy: 0.7946\n",
      "Epoch 83/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2579 - accuracy: 0.9144 - val_loss: 0.8132 - val_accuracy: 0.7904\n",
      "Epoch 84/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2533 - accuracy: 0.9170 - val_loss: 0.7740 - val_accuracy: 0.7978\n",
      "Epoch 85/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2570 - accuracy: 0.9159 - val_loss: 0.8303 - val_accuracy: 0.7952\n",
      "Epoch 86/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2455 - accuracy: 0.9183 - val_loss: 0.7997 - val_accuracy: 0.8004\n",
      "Epoch 87/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2576 - accuracy: 0.9154 - val_loss: 0.8193 - val_accuracy: 0.7940\n",
      "Epoch 88/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2476 - accuracy: 0.9170 - val_loss: 0.8192 - val_accuracy: 0.7976\n",
      "Epoch 89/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2475 - accuracy: 0.9165 - val_loss: 0.8785 - val_accuracy: 0.8046\n",
      "Epoch 90/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2521 - accuracy: 0.9155 - val_loss: 0.8304 - val_accuracy: 0.7856\n",
      "Epoch 91/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2554 - accuracy: 0.9157 - val_loss: 0.7961 - val_accuracy: 0.7956\n",
      "Epoch 92/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2456 - accuracy: 0.9196 - val_loss: 0.7950 - val_accuracy: 0.8008\n",
      "Epoch 93/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2521 - accuracy: 0.9179 - val_loss: 0.7966 - val_accuracy: 0.7990\n",
      "Epoch 94/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2461 - accuracy: 0.9189 - val_loss: 0.8231 - val_accuracy: 0.7932\n",
      "Epoch 95/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2427 - accuracy: 0.9209 - val_loss: 0.8697 - val_accuracy: 0.7944\n",
      "Epoch 96/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2480 - accuracy: 0.9196 - val_loss: 0.8672 - val_accuracy: 0.8036\n",
      "Epoch 97/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2486 - accuracy: 0.9170 - val_loss: 0.8154 - val_accuracy: 0.8034\n",
      "Epoch 98/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2495 - accuracy: 0.9184 - val_loss: 0.7921 - val_accuracy: 0.7992\n",
      "Epoch 99/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2436 - accuracy: 0.9200 - val_loss: 0.9106 - val_accuracy: 0.7918\n",
      "Epoch 100/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 0.2489 - accuracy: 0.9176 - val_loss: 0.8528 - val_accuracy: 0.7956\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 382.1964 - accuracy: 0.5045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[382.1963806152344, 0.5044999718666077]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = Input(shape=(depth, height, width))\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "conv_1 = Convolution2D(conv_depth_1, (kernel_size, kernel_size), padding='same', activation='relu')(inp) #Сверточный слой\n",
    "conv_2 = Convolution2D(conv_depth_1, (kernel_size, kernel_size), padding='same', activation='relu')(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size), padding='same')(conv_2) # Слой подвыборки\n",
    "drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
    "conv_3 = Convolution2D(conv_depth_2, (kernel_size, kernel_size), padding='same', activation='relu')(drop_1)\n",
    "conv_4 = Convolution2D(conv_depth_2, (kernel_size, kernel_size), padding='same', activation='relu')(conv_3)\n",
    "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size), padding='same')(conv_4)\n",
    "drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "# Now flatten to 1D, apply FC -> ReLU (with dropout) -> softmax\n",
    "flat = Flatten()(drop_2) # Трансформируем в одномерный вектор\n",
    "hidden = Dense(hidden_size, activation='relu')(flat)\n",
    "drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "out = Dense(num_classes, activation='softmax')(drop_3)\n",
    "\n",
    "model = Model(inp, out) # Укажем слой входа и слой выхода\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "          verbose=1, validation_split=0.1) # Оставляем 10 процентов для тестирования\n",
    "# Оценим модель\n",
    "model.evaluate(X_test, Y_test, verbose=1) # Оценим обученную модель на тестовых данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bb9eef",
   "metadata": {},
   "source": [
    "Исследуем сеть без слоя Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bd8e2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 1.4815 - accuracy: 0.4624 - val_loss: 1.0791 - val_accuracy: 0.6204\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 1.0718 - accuracy: 0.6187 - val_loss: 0.9181 - val_accuracy: 0.6696\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 0.8926 - accuracy: 0.6863 - val_loss: 0.8144 - val_accuracy: 0.7218\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 0.7479 - accuracy: 0.7365 - val_loss: 0.7690 - val_accuracy: 0.7308\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.6243 - accuracy: 0.7797 - val_loss: 0.7633 - val_accuracy: 0.7436\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 0.5111 - accuracy: 0.8194 - val_loss: 0.8104 - val_accuracy: 0.7388\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 0.4133 - accuracy: 0.8549 - val_loss: 0.8389 - val_accuracy: 0.7326\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 0.3461 - accuracy: 0.8770 - val_loss: 0.8423 - val_accuracy: 0.7566\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 0.2878 - accuracy: 0.8982 - val_loss: 1.0039 - val_accuracy: 0.7484\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 0.2599 - accuracy: 0.9101 - val_loss: 1.0117 - val_accuracy: 0.7468\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 0.2243 - accuracy: 0.9218 - val_loss: 1.0646 - val_accuracy: 0.7494\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 0.2049 - accuracy: 0.9296 - val_loss: 1.1391 - val_accuracy: 0.7382\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 0.1805 - accuracy: 0.9370 - val_loss: 1.2540 - val_accuracy: 0.7356\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 0.1735 - accuracy: 0.9405 - val_loss: 1.2321 - val_accuracy: 0.7338\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 72s 52ms/step - loss: 0.1636 - accuracy: 0.9438 - val_loss: 1.4149 - val_accuracy: 0.7398\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.1616 - accuracy: 0.9451 - val_loss: 1.2510 - val_accuracy: 0.7432\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.1474 - accuracy: 0.9521 - val_loss: 1.3978 - val_accuracy: 0.7300\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.1508 - accuracy: 0.9508 - val_loss: 1.3678 - val_accuracy: 0.7452\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.1307 - accuracy: 0.9566 - val_loss: 1.4672 - val_accuracy: 0.7456\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.1379 - accuracy: 0.9551 - val_loss: 1.3343 - val_accuracy: 0.7454\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 72s 52ms/step - loss: 0.1303 - accuracy: 0.9570 - val_loss: 1.5105 - val_accuracy: 0.7412\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.1293 - accuracy: 0.9578 - val_loss: 1.5557 - val_accuracy: 0.7362\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.1279 - accuracy: 0.9597 - val_loss: 1.4210 - val_accuracy: 0.7348\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.1185 - accuracy: 0.9622 - val_loss: 1.5680 - val_accuracy: 0.7420\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.1187 - accuracy: 0.9613 - val_loss: 1.3824 - val_accuracy: 0.7422\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 74s 52ms/step - loss: 0.1169 - accuracy: 0.9624 - val_loss: 1.6204 - val_accuracy: 0.7360\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.1119 - accuracy: 0.9641 - val_loss: 1.5410 - val_accuracy: 0.7390\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.1136 - accuracy: 0.9643 - val_loss: 1.7406 - val_accuracy: 0.7376\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.1143 - accuracy: 0.9630 - val_loss: 1.5422 - val_accuracy: 0.7376\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.1046 - accuracy: 0.9657 - val_loss: 1.6189 - val_accuracy: 0.7324\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.1120 - accuracy: 0.9649 - val_loss: 1.7009 - val_accuracy: 0.7390\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.1013 - accuracy: 0.9673 - val_loss: 2.1181 - val_accuracy: 0.7352\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.1082 - accuracy: 0.9667 - val_loss: 1.9293 - val_accuracy: 0.7280\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.1032 - accuracy: 0.9685 - val_loss: 1.8735 - val_accuracy: 0.7264\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.1001 - accuracy: 0.9681 - val_loss: 1.7654 - val_accuracy: 0.7422\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.1050 - accuracy: 0.9680 - val_loss: 1.7020 - val_accuracy: 0.7388\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0982 - accuracy: 0.9693 - val_loss: 1.9036 - val_accuracy: 0.7420\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.1007 - accuracy: 0.9705 - val_loss: 1.6743 - val_accuracy: 0.7428\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0921 - accuracy: 0.9716 - val_loss: 1.7690 - val_accuracy: 0.7354\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0929 - accuracy: 0.9715 - val_loss: 2.0164 - val_accuracy: 0.7340\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0921 - accuracy: 0.9712 - val_loss: 2.1421 - val_accuracy: 0.7314\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.1020 - accuracy: 0.9702 - val_loss: 1.8173 - val_accuracy: 0.7454\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.0988 - accuracy: 0.9704 - val_loss: 2.0105 - val_accuracy: 0.7246\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0898 - accuracy: 0.9727 - val_loss: 2.1493 - val_accuracy: 0.7416\n",
      "Epoch 45/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0908 - accuracy: 0.9729 - val_loss: 2.0079 - val_accuracy: 0.7248\n",
      "Epoch 46/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0986 - accuracy: 0.9708 - val_loss: 2.0292 - val_accuracy: 0.7384\n",
      "Epoch 47/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0900 - accuracy: 0.9727 - val_loss: 2.1072 - val_accuracy: 0.7402\n",
      "Epoch 48/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0867 - accuracy: 0.9743 - val_loss: 2.5474 - val_accuracy: 0.7440\n",
      "Epoch 49/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0899 - accuracy: 0.9735 - val_loss: 1.9551 - val_accuracy: 0.7370\n",
      "Epoch 50/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0914 - accuracy: 0.9727 - val_loss: 2.1284 - val_accuracy: 0.7386\n",
      "Epoch 51/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0860 - accuracy: 0.9738 - val_loss: 1.9670 - val_accuracy: 0.7264\n",
      "Epoch 52/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0931 - accuracy: 0.9731 - val_loss: 2.0815 - val_accuracy: 0.7306\n",
      "Epoch 53/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0909 - accuracy: 0.9743 - val_loss: 2.0021 - val_accuracy: 0.7182\n",
      "Epoch 54/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0838 - accuracy: 0.9758 - val_loss: 2.1468 - val_accuracy: 0.7358\n",
      "Epoch 55/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0919 - accuracy: 0.9721 - val_loss: 1.9330 - val_accuracy: 0.7290\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0895 - accuracy: 0.9748 - val_loss: 2.1292 - val_accuracy: 0.7290\n",
      "Epoch 57/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0818 - accuracy: 0.9763 - val_loss: 2.3687 - val_accuracy: 0.7302\n",
      "Epoch 58/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0868 - accuracy: 0.9752 - val_loss: 2.0340 - val_accuracy: 0.7334\n",
      "Epoch 59/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0898 - accuracy: 0.9758 - val_loss: 2.0638 - val_accuracy: 0.7336\n",
      "Epoch 60/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0911 - accuracy: 0.9743 - val_loss: 2.3081 - val_accuracy: 0.7342\n",
      "Epoch 61/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0775 - accuracy: 0.9775 - val_loss: 2.2909 - val_accuracy: 0.7314\n",
      "Epoch 62/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0884 - accuracy: 0.9750 - val_loss: 2.0016 - val_accuracy: 0.7218\n",
      "Epoch 63/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0870 - accuracy: 0.9762 - val_loss: 2.3534 - val_accuracy: 0.7358\n",
      "Epoch 64/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0866 - accuracy: 0.9755 - val_loss: 2.3203 - val_accuracy: 0.7322\n",
      "Epoch 65/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0846 - accuracy: 0.9755 - val_loss: 2.2168 - val_accuracy: 0.7394\n",
      "Epoch 66/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0876 - accuracy: 0.9760 - val_loss: 2.3185 - val_accuracy: 0.7262\n",
      "Epoch 67/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0915 - accuracy: 0.9745 - val_loss: 2.0264 - val_accuracy: 0.7340\n",
      "Epoch 68/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0904 - accuracy: 0.9752 - val_loss: 2.5016 - val_accuracy: 0.7410\n",
      "Epoch 69/100\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 0.0851 - accuracy: 0.9774 - val_loss: 2.3135 - val_accuracy: 0.7376\n",
      "Epoch 70/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0876 - accuracy: 0.9756 - val_loss: 2.1295 - val_accuracy: 0.7278\n",
      "Epoch 71/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0826 - accuracy: 0.9773 - val_loss: 2.4449 - val_accuracy: 0.7354\n",
      "Epoch 72/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0908 - accuracy: 0.9756 - val_loss: 2.0899 - val_accuracy: 0.7316\n",
      "Epoch 73/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0874 - accuracy: 0.9749 - val_loss: 2.5442 - val_accuracy: 0.7238\n",
      "Epoch 74/100\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 0.0873 - accuracy: 0.9768 - val_loss: 2.6836 - val_accuracy: 0.7372\n",
      "Epoch 75/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0840 - accuracy: 0.9776 - val_loss: 2.3838 - val_accuracy: 0.7240\n",
      "Epoch 76/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0845 - accuracy: 0.9777 - val_loss: 2.7223 - val_accuracy: 0.7318\n",
      "Epoch 77/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0853 - accuracy: 0.9773 - val_loss: 2.5233 - val_accuracy: 0.7352\n",
      "Epoch 78/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0900 - accuracy: 0.9767 - val_loss: 2.7835 - val_accuracy: 0.7334\n",
      "Epoch 79/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0886 - accuracy: 0.9756 - val_loss: 2.3465 - val_accuracy: 0.7176\n",
      "Epoch 80/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0867 - accuracy: 0.9759 - val_loss: 2.5199 - val_accuracy: 0.7324\n",
      "Epoch 81/100\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 0.0818 - accuracy: 0.9776 - val_loss: 2.3136 - val_accuracy: 0.7272\n",
      "Epoch 82/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0809 - accuracy: 0.9782 - val_loss: 2.5103 - val_accuracy: 0.7280\n",
      "Epoch 83/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0784 - accuracy: 0.9788 - val_loss: 2.7724 - val_accuracy: 0.7226\n",
      "Epoch 84/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.0892 - accuracy: 0.9766 - val_loss: 2.4391 - val_accuracy: 0.7242\n",
      "Epoch 85/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0768 - accuracy: 0.9788 - val_loss: 2.4263 - val_accuracy: 0.7360\n",
      "Epoch 86/100\n",
      "1407/1407 [==============================] - 72s 52ms/step - loss: 0.0881 - accuracy: 0.9770 - val_loss: 2.7699 - val_accuracy: 0.7292\n",
      "Epoch 87/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0900 - accuracy: 0.9758 - val_loss: 2.5196 - val_accuracy: 0.7346\n",
      "Epoch 88/100\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 0.0833 - accuracy: 0.9775 - val_loss: 2.9770 - val_accuracy: 0.7306\n",
      "Epoch 89/100\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 0.0819 - accuracy: 0.9785 - val_loss: 2.5754 - val_accuracy: 0.7284\n",
      "Epoch 90/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0864 - accuracy: 0.9772 - val_loss: 2.2737 - val_accuracy: 0.7332\n",
      "Epoch 91/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0916 - accuracy: 0.9776 - val_loss: 2.9912 - val_accuracy: 0.7252\n",
      "Epoch 92/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0877 - accuracy: 0.9772 - val_loss: 3.4171 - val_accuracy: 0.7240\n",
      "Epoch 93/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0792 - accuracy: 0.9794 - val_loss: 2.8729 - val_accuracy: 0.7248\n",
      "Epoch 94/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0847 - accuracy: 0.9784 - val_loss: 2.5793 - val_accuracy: 0.7282\n",
      "Epoch 95/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0865 - accuracy: 0.9782 - val_loss: 2.7287 - val_accuracy: 0.7386\n",
      "Epoch 96/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0854 - accuracy: 0.9776 - val_loss: 2.6796 - val_accuracy: 0.7238\n",
      "Epoch 97/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0830 - accuracy: 0.9788 - val_loss: 2.4040 - val_accuracy: 0.7298\n",
      "Epoch 98/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0842 - accuracy: 0.9783 - val_loss: 2.7029 - val_accuracy: 0.7360\n",
      "Epoch 99/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0877 - accuracy: 0.9772 - val_loss: 2.4496 - val_accuracy: 0.7258\n",
      "Epoch 100/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.0872 - accuracy: 0.9770 - val_loss: 2.4564 - val_accuracy: 0.7210\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 839.2358 - accuracy: 0.4676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[839.2357788085938, 0.4675999879837036]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = Input(shape=(depth, height, width))\n",
    "# Conv [32] -> Conv [32] -> Pool\n",
    "conv_1 = Convolution2D(conv_depth_1, (kernel_size, kernel_size), padding='same', activation='relu')(inp)\n",
    "conv_2 = Convolution2D(conv_depth_1, (kernel_size, kernel_size), padding='same', activation='relu')(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size), padding='same')(conv_2)\n",
    "\n",
    "# Conv [64] -> Conv [64] -> Pool\n",
    "conv_3 = Convolution2D(conv_depth_2, (kernel_size, kernel_size), padding='same', activation='relu')(pool_1)\n",
    "conv_4 = Convolution2D(conv_depth_2, (kernel_size, kernel_size), padding='same', activation='relu')(conv_3)\n",
    "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size), padding='same')(conv_4)\n",
    "\n",
    "# Now flatten to 1D, apply FC -> ReLU -> softmax\n",
    "flat = Flatten()(conv_4) # Трансформируем в одномерный вектор\n",
    "hidden = Dense(hidden_size, activation='relu')(flat)\n",
    "drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "out = Dense(num_classes, activation='softmax')(drop_3)\n",
    "\n",
    "model = Model(inp, out) # Укажем слой входа и слой выхода\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "          verbose=1, validation_split=0.1) # Оставляем 10 процентов для тестирования\n",
    "\n",
    "model.evaluate(X_test, Y_test, verbose=1) # Оценим обученную модель на тестовых данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2acc916",
   "metadata": {},
   "source": [
    "Уменьшим размер ядра свертки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b18966d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 1.6956 - accuracy: 0.3848 - val_loss: 1.5026 - val_accuracy: 0.4716\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 1.4595 - accuracy: 0.4755 - val_loss: 1.3295 - val_accuracy: 0.5256\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 1.3873 - accuracy: 0.5007 - val_loss: 1.3045 - val_accuracy: 0.5364\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 1.3323 - accuracy: 0.5240 - val_loss: 1.2554 - val_accuracy: 0.5570\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 1.2919 - accuracy: 0.5385 - val_loss: 1.2222 - val_accuracy: 0.5772\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 1.2617 - accuracy: 0.5506 - val_loss: 1.2142 - val_accuracy: 0.5720\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 1.2246 - accuracy: 0.5671 - val_loss: 1.1779 - val_accuracy: 0.5950\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 1.1919 - accuracy: 0.5767 - val_loss: 1.1688 - val_accuracy: 0.5856\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 1.1652 - accuracy: 0.5854 - val_loss: 1.1610 - val_accuracy: 0.5922\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 1.1411 - accuracy: 0.5939 - val_loss: 1.1370 - val_accuracy: 0.6046\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 1.1105 - accuracy: 0.6035 - val_loss: 1.1752 - val_accuracy: 0.5962\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 1.0961 - accuracy: 0.6090 - val_loss: 1.1328 - val_accuracy: 0.6044\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 1.0656 - accuracy: 0.6209 - val_loss: 1.1709 - val_accuracy: 0.5948\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 1.0494 - accuracy: 0.6250 - val_loss: 1.1240 - val_accuracy: 0.6100\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 1.0350 - accuracy: 0.6309 - val_loss: 1.1183 - val_accuracy: 0.6104\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 1.0161 - accuracy: 0.6400 - val_loss: 1.1136 - val_accuracy: 0.6196\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 0.9956 - accuracy: 0.6427 - val_loss: 1.1130 - val_accuracy: 0.6112\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 0.9806 - accuracy: 0.6501 - val_loss: 1.1646 - val_accuracy: 0.5910\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 0.9593 - accuracy: 0.6585 - val_loss: 1.1704 - val_accuracy: 0.5980\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 0.9444 - accuracy: 0.6616 - val_loss: 1.1043 - val_accuracy: 0.6162\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 0.9273 - accuracy: 0.6661 - val_loss: 1.1373 - val_accuracy: 0.6140\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 0.9183 - accuracy: 0.6694 - val_loss: 1.1280 - val_accuracy: 0.6138\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 0.8927 - accuracy: 0.6776 - val_loss: 1.1254 - val_accuracy: 0.6138\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 0.8892 - accuracy: 0.6797 - val_loss: 1.1325 - val_accuracy: 0.6130\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 0.8730 - accuracy: 0.6861 - val_loss: 1.1157 - val_accuracy: 0.6164\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 0.8470 - accuracy: 0.6938 - val_loss: 1.1287 - val_accuracy: 0.6062\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.8405 - accuracy: 0.6976 - val_loss: 1.1184 - val_accuracy: 0.6194\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.8313 - accuracy: 0.6989 - val_loss: 1.1095 - val_accuracy: 0.6250\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 0.8192 - accuracy: 0.7032 - val_loss: 1.1052 - val_accuracy: 0.6204\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.8055 - accuracy: 0.7072 - val_loss: 1.1471 - val_accuracy: 0.6146\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.7968 - accuracy: 0.7120 - val_loss: 1.1026 - val_accuracy: 0.6230\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 0.7829 - accuracy: 0.7155 - val_loss: 1.1460 - val_accuracy: 0.6150\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.7745 - accuracy: 0.7178 - val_loss: 1.1500 - val_accuracy: 0.6136\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 0.7645 - accuracy: 0.7256 - val_loss: 1.1824 - val_accuracy: 0.6148\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.7528 - accuracy: 0.7288 - val_loss: 1.1572 - val_accuracy: 0.6112\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.7441 - accuracy: 0.7294 - val_loss: 1.1710 - val_accuracy: 0.6172\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 0.7389 - accuracy: 0.7312 - val_loss: 1.1541 - val_accuracy: 0.6240\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 0.7216 - accuracy: 0.7390 - val_loss: 1.1774 - val_accuracy: 0.6150\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.7036 - accuracy: 0.7424 - val_loss: 1.1566 - val_accuracy: 0.6184\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.7019 - accuracy: 0.7440 - val_loss: 1.2184 - val_accuracy: 0.6054\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.6949 - accuracy: 0.7472 - val_loss: 1.1702 - val_accuracy: 0.6174\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.6914 - accuracy: 0.7480 - val_loss: 1.1965 - val_accuracy: 0.6030\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.6798 - accuracy: 0.7532 - val_loss: 1.2385 - val_accuracy: 0.6060\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.6704 - accuracy: 0.7580 - val_loss: 1.2146 - val_accuracy: 0.6060\n",
      "Epoch 45/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.6659 - accuracy: 0.7586 - val_loss: 1.1653 - val_accuracy: 0.6202\n",
      "Epoch 46/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.6619 - accuracy: 0.7608 - val_loss: 1.2426 - val_accuracy: 0.6070\n",
      "Epoch 47/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.6485 - accuracy: 0.7642 - val_loss: 1.1826 - val_accuracy: 0.6184\n",
      "Epoch 48/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.6455 - accuracy: 0.7640 - val_loss: 1.2208 - val_accuracy: 0.6238\n",
      "Epoch 49/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.6405 - accuracy: 0.7670 - val_loss: 1.2078 - val_accuracy: 0.6134\n",
      "Epoch 50/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 0.6372 - accuracy: 0.7667 - val_loss: 1.1948 - val_accuracy: 0.6246\n",
      "Epoch 51/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 0.6231 - accuracy: 0.7730 - val_loss: 1.2690 - val_accuracy: 0.6072\n",
      "Epoch 52/100\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 0.6201 - accuracy: 0.7739 - val_loss: 1.2687 - val_accuracy: 0.6050\n",
      "Epoch 53/100\n",
      "1407/1407 [==============================] - 25s 18ms/step - loss: 0.6129 - accuracy: 0.7799 - val_loss: 1.2203 - val_accuracy: 0.6196\n",
      "Epoch 54/100\n",
      "1407/1407 [==============================] - 25s 18ms/step - loss: 0.6076 - accuracy: 0.7767 - val_loss: 1.2532 - val_accuracy: 0.6094\n",
      "Epoch 55/100\n",
      "1407/1407 [==============================] - 25s 18ms/step - loss: 0.6041 - accuracy: 0.7811 - val_loss: 1.2445 - val_accuracy: 0.6192\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 25s 18ms/step - loss: 0.6048 - accuracy: 0.7823 - val_loss: 1.2819 - val_accuracy: 0.6100\n",
      "Epoch 57/100\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 0.5950 - accuracy: 0.7837 - val_loss: 1.3249 - val_accuracy: 0.5952\n",
      "Epoch 58/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.5906 - accuracy: 0.7864 - val_loss: 1.3023 - val_accuracy: 0.6060\n",
      "Epoch 59/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.5817 - accuracy: 0.7887 - val_loss: 1.2957 - val_accuracy: 0.6034\n",
      "Epoch 60/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.5768 - accuracy: 0.7885 - val_loss: 1.2687 - val_accuracy: 0.6120\n",
      "Epoch 61/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.5715 - accuracy: 0.7894 - val_loss: 1.2848 - val_accuracy: 0.6174\n",
      "Epoch 62/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.5718 - accuracy: 0.7923 - val_loss: 1.3302 - val_accuracy: 0.6026\n",
      "Epoch 63/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.5634 - accuracy: 0.7934 - val_loss: 1.2799 - val_accuracy: 0.6006\n",
      "Epoch 64/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.5648 - accuracy: 0.7916 - val_loss: 1.3034 - val_accuracy: 0.6078\n",
      "Epoch 65/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 0.5582 - accuracy: 0.7964 - val_loss: 1.2786 - val_accuracy: 0.6182\n",
      "Epoch 66/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.5541 - accuracy: 0.7971 - val_loss: 1.2835 - val_accuracy: 0.6072\n",
      "Epoch 67/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.5440 - accuracy: 0.8018 - val_loss: 1.3058 - val_accuracy: 0.5994\n",
      "Epoch 68/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 0.5444 - accuracy: 0.8007 - val_loss: 1.2876 - val_accuracy: 0.6104\n",
      "Epoch 69/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.5317 - accuracy: 0.8075 - val_loss: 1.3223 - val_accuracy: 0.6048\n",
      "Epoch 70/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 0.5361 - accuracy: 0.8034 - val_loss: 1.3199 - val_accuracy: 0.6050\n",
      "Epoch 71/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.5300 - accuracy: 0.8066 - val_loss: 1.3419 - val_accuracy: 0.5968\n",
      "Epoch 72/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.5252 - accuracy: 0.8081 - val_loss: 1.2756 - val_accuracy: 0.6070\n",
      "Epoch 73/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.5197 - accuracy: 0.8103 - val_loss: 1.3169 - val_accuracy: 0.6004\n",
      "Epoch 74/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.5212 - accuracy: 0.8121 - val_loss: 1.3893 - val_accuracy: 0.6012\n",
      "Epoch 75/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.5227 - accuracy: 0.8113 - val_loss: 1.3372 - val_accuracy: 0.6086\n",
      "Epoch 76/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.5157 - accuracy: 0.8112 - val_loss: 1.4172 - val_accuracy: 0.5892\n",
      "Epoch 77/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.5115 - accuracy: 0.8144 - val_loss: 1.3310 - val_accuracy: 0.5998\n",
      "Epoch 78/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.5106 - accuracy: 0.8150 - val_loss: 1.3716 - val_accuracy: 0.5914\n",
      "Epoch 79/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.5019 - accuracy: 0.8166 - val_loss: 1.3476 - val_accuracy: 0.5980\n",
      "Epoch 80/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.5030 - accuracy: 0.8172 - val_loss: 1.4022 - val_accuracy: 0.5978\n",
      "Epoch 81/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.4956 - accuracy: 0.8206 - val_loss: 1.3726 - val_accuracy: 0.6030\n",
      "Epoch 82/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.4999 - accuracy: 0.8193 - val_loss: 1.3509 - val_accuracy: 0.6134\n",
      "Epoch 83/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.4958 - accuracy: 0.8186 - val_loss: 1.2985 - val_accuracy: 0.6116\n",
      "Epoch 84/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 0.4938 - accuracy: 0.8233 - val_loss: 1.2613 - val_accuracy: 0.6238\n",
      "Epoch 85/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 0.4761 - accuracy: 0.8274 - val_loss: 1.3822 - val_accuracy: 0.6040\n",
      "Epoch 86/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.4849 - accuracy: 0.8233 - val_loss: 1.3562 - val_accuracy: 0.6108\n",
      "Epoch 87/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.4830 - accuracy: 0.8255 - val_loss: 1.3345 - val_accuracy: 0.6076\n",
      "Epoch 88/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.4706 - accuracy: 0.8281 - val_loss: 1.3676 - val_accuracy: 0.6064\n",
      "Epoch 89/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.4817 - accuracy: 0.8267 - val_loss: 1.3191 - val_accuracy: 0.6108\n",
      "Epoch 90/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.4677 - accuracy: 0.8312 - val_loss: 1.3307 - val_accuracy: 0.6124\n",
      "Epoch 91/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.4729 - accuracy: 0.8283 - val_loss: 1.3683 - val_accuracy: 0.6060\n",
      "Epoch 92/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.4654 - accuracy: 0.8316 - val_loss: 1.3895 - val_accuracy: 0.6086\n",
      "Epoch 93/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.4749 - accuracy: 0.8289 - val_loss: 1.3327 - val_accuracy: 0.6134\n",
      "Epoch 94/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.4643 - accuracy: 0.8337 - val_loss: 1.3867 - val_accuracy: 0.6078\n",
      "Epoch 95/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.4682 - accuracy: 0.8300 - val_loss: 1.3561 - val_accuracy: 0.6026\n",
      "Epoch 96/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.4592 - accuracy: 0.8337 - val_loss: 1.3603 - val_accuracy: 0.5982\n",
      "Epoch 97/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.4578 - accuracy: 0.8348 - val_loss: 1.3184 - val_accuracy: 0.6070\n",
      "Epoch 98/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.4545 - accuracy: 0.8337 - val_loss: 1.3369 - val_accuracy: 0.6072\n",
      "Epoch 99/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.4482 - accuracy: 0.8384 - val_loss: 1.3851 - val_accuracy: 0.6014\n",
      "Epoch 100/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.4533 - accuracy: 0.8334 - val_loss: 1.3842 - val_accuracy: 0.6010\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 2702.1101 - accuracy: 0.1092\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2702.110107421875, 0.10920000076293945]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_size = 1 # размер ядра в свертывающих слоях\n",
    "\n",
    "inp = Input(shape=(depth, height, width))\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "conv_1 = Convolution2D(conv_depth_1, (kernel_size, kernel_size), padding='same', activation='relu')(inp)\n",
    "conv_2 = Convolution2D(conv_depth_1, (kernel_size, kernel_size), padding='same', activation='relu')(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size), padding='same')(conv_2)\n",
    "drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
    "conv_3 = Convolution2D(conv_depth_2, (kernel_size, kernel_size), padding='same', activation='relu')(drop_1)\n",
    "conv_4 = Convolution2D(conv_depth_2, (kernel_size, kernel_size), padding='same', activation='relu')(conv_3)\n",
    "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size), padding='same')(conv_4)\n",
    "drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "# Now flatten to 1D, apply FC -> ReLU (with dropout) -> softmax\n",
    "flat = Flatten()(drop_2) # Трансформируем в одномерный вектор\n",
    "hidden = Dense(hidden_size, activation='relu')(flat)\n",
    "drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "out = Dense(num_classes, activation='softmax')(drop_3)\n",
    "\n",
    "model = Model(inp, out) # Укажем слой входа и слой выхода\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "          verbose=1, validation_split=0.1) # Оставляем 10 процентов для тестирования\n",
    "\n",
    "model.evaluate(X_test, Y_test, verbose=1) # Оценим обученную модель на тестовых данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a76a7d7",
   "metadata": {},
   "source": [
    "Увеличим размер ядра свертки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bac18fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 76s 54ms/step - loss: 1.5693 - accuracy: 0.4301 - val_loss: 1.1885 - val_accuracy: 0.5686\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 75s 54ms/step - loss: 1.1557 - accuracy: 0.5879 - val_loss: 0.9484 - val_accuracy: 0.6688\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.9920 - accuracy: 0.6475 - val_loss: 0.8591 - val_accuracy: 0.7010\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.8956 - accuracy: 0.6855 - val_loss: 0.8086 - val_accuracy: 0.7134\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.8300 - accuracy: 0.7089 - val_loss: 0.7367 - val_accuracy: 0.7412\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 75s 54ms/step - loss: 0.7737 - accuracy: 0.7275 - val_loss: 0.7590 - val_accuracy: 0.7410\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 76s 54ms/step - loss: 0.7363 - accuracy: 0.7433 - val_loss: 0.7315 - val_accuracy: 0.7518\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 75s 54ms/step - loss: 0.7014 - accuracy: 0.7535 - val_loss: 0.6985 - val_accuracy: 0.7588\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 75s 54ms/step - loss: 0.6683 - accuracy: 0.7653 - val_loss: 0.6921 - val_accuracy: 0.7636\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.6345 - accuracy: 0.7768 - val_loss: 0.7041 - val_accuracy: 0.7654\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.6203 - accuracy: 0.7807 - val_loss: 0.6864 - val_accuracy: 0.7636\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 76s 54ms/step - loss: 0.5910 - accuracy: 0.7930 - val_loss: 0.6856 - val_accuracy: 0.7722\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.5706 - accuracy: 0.7991 - val_loss: 0.7223 - val_accuracy: 0.7560\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.5504 - accuracy: 0.8053 - val_loss: 0.7071 - val_accuracy: 0.7678\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.5415 - accuracy: 0.8084 - val_loss: 0.7292 - val_accuracy: 0.7644\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 74s 52ms/step - loss: 0.5220 - accuracy: 0.8170 - val_loss: 0.6930 - val_accuracy: 0.7728\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.5068 - accuracy: 0.8253 - val_loss: 0.7011 - val_accuracy: 0.7766\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.4986 - accuracy: 0.8262 - val_loss: 0.7093 - val_accuracy: 0.7756\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 75s 54ms/step - loss: 0.4819 - accuracy: 0.8310 - val_loss: 0.7524 - val_accuracy: 0.7684\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 75s 54ms/step - loss: 0.4801 - accuracy: 0.8319 - val_loss: 0.6937 - val_accuracy: 0.7784\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.4643 - accuracy: 0.8343 - val_loss: 0.7506 - val_accuracy: 0.7750\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.4563 - accuracy: 0.8412 - val_loss: 0.7096 - val_accuracy: 0.7826\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 75s 54ms/step - loss: 0.4602 - accuracy: 0.8385 - val_loss: 0.7145 - val_accuracy: 0.7786\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 76s 54ms/step - loss: 0.4443 - accuracy: 0.8453 - val_loss: 0.7156 - val_accuracy: 0.7728\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 75s 54ms/step - loss: 0.4357 - accuracy: 0.8470 - val_loss: 0.7318 - val_accuracy: 0.7760\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.4347 - accuracy: 0.8484 - val_loss: 0.7314 - val_accuracy: 0.7836\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.4240 - accuracy: 0.8511 - val_loss: 0.7317 - val_accuracy: 0.7778\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 75s 54ms/step - loss: 0.4119 - accuracy: 0.8579 - val_loss: 0.7435 - val_accuracy: 0.7860\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 75s 54ms/step - loss: 0.4192 - accuracy: 0.8551 - val_loss: 0.7395 - val_accuracy: 0.7814\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 76s 54ms/step - loss: 0.4169 - accuracy: 0.8553 - val_loss: 0.6993 - val_accuracy: 0.7826\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 76s 54ms/step - loss: 0.4121 - accuracy: 0.8578 - val_loss: 0.7393 - val_accuracy: 0.7746\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 76s 54ms/step - loss: 0.4005 - accuracy: 0.8600 - val_loss: 0.7476 - val_accuracy: 0.7792\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 76s 54ms/step - loss: 0.3921 - accuracy: 0.8642 - val_loss: 0.7603 - val_accuracy: 0.7882\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.3981 - accuracy: 0.8622 - val_loss: 0.7422 - val_accuracy: 0.7822\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.3939 - accuracy: 0.8644 - val_loss: 0.7198 - val_accuracy: 0.7890\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.3847 - accuracy: 0.8690 - val_loss: 0.7637 - val_accuracy: 0.7888\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 76s 54ms/step - loss: 0.3831 - accuracy: 0.8687 - val_loss: 0.8230 - val_accuracy: 0.7832\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.3848 - accuracy: 0.8688 - val_loss: 0.7443 - val_accuracy: 0.7874\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.3720 - accuracy: 0.8726 - val_loss: 0.8116 - val_accuracy: 0.7802\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.3684 - accuracy: 0.8737 - val_loss: 0.8381 - val_accuracy: 0.7918\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.3760 - accuracy: 0.8710 - val_loss: 0.8790 - val_accuracy: 0.7708\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.3720 - accuracy: 0.8724 - val_loss: 0.7757 - val_accuracy: 0.7790\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.3595 - accuracy: 0.8772 - val_loss: 0.7615 - val_accuracy: 0.7868\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.3608 - accuracy: 0.8751 - val_loss: 0.8102 - val_accuracy: 0.7820\n",
      "Epoch 45/100\n",
      "1407/1407 [==============================] - 75s 54ms/step - loss: 0.3713 - accuracy: 0.8731 - val_loss: 0.7627 - val_accuracy: 0.7828\n",
      "Epoch 46/100\n",
      "1407/1407 [==============================] - 76s 54ms/step - loss: 0.3513 - accuracy: 0.8798 - val_loss: 0.8025 - val_accuracy: 0.7908\n",
      "Epoch 47/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.3509 - accuracy: 0.8792 - val_loss: 0.7617 - val_accuracy: 0.7886\n",
      "Epoch 48/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.3570 - accuracy: 0.8783 - val_loss: 0.7755 - val_accuracy: 0.7852\n",
      "Epoch 49/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.3582 - accuracy: 0.8786 - val_loss: 0.7515 - val_accuracy: 0.7936\n",
      "Epoch 50/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.3485 - accuracy: 0.8821 - val_loss: 0.7644 - val_accuracy: 0.7746\n",
      "Epoch 51/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.3409 - accuracy: 0.8835 - val_loss: 0.7986 - val_accuracy: 0.7954\n",
      "Epoch 52/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.3468 - accuracy: 0.8816 - val_loss: 0.8042 - val_accuracy: 0.7802\n",
      "Epoch 53/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.3432 - accuracy: 0.8845 - val_loss: 0.8717 - val_accuracy: 0.7738\n",
      "Epoch 54/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.3449 - accuracy: 0.8837 - val_loss: 0.7778 - val_accuracy: 0.7798\n",
      "Epoch 55/100\n",
      "1407/1407 [==============================] - 75s 54ms/step - loss: 0.3443 - accuracy: 0.8841 - val_loss: 0.7431 - val_accuracy: 0.7868\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 75s 54ms/step - loss: 0.3343 - accuracy: 0.8856 - val_loss: 0.8218 - val_accuracy: 0.7894\n",
      "Epoch 57/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.3328 - accuracy: 0.8879 - val_loss: 0.8341 - val_accuracy: 0.7842\n",
      "Epoch 58/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.3391 - accuracy: 0.8849 - val_loss: 0.7798 - val_accuracy: 0.7802\n",
      "Epoch 59/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.3353 - accuracy: 0.8885 - val_loss: 0.8454 - val_accuracy: 0.7836\n",
      "Epoch 60/100\n",
      "1407/1407 [==============================] - 75s 54ms/step - loss: 0.3382 - accuracy: 0.8872 - val_loss: 0.8298 - val_accuracy: 0.7870\n",
      "Epoch 61/100\n",
      "1407/1407 [==============================] - 76s 54ms/step - loss: 0.3362 - accuracy: 0.8876 - val_loss: 0.8381 - val_accuracy: 0.7790\n",
      "Epoch 62/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.3299 - accuracy: 0.8887 - val_loss: 0.8531 - val_accuracy: 0.7850\n",
      "Epoch 63/100\n",
      "1407/1407 [==============================] - 76s 54ms/step - loss: 0.3394 - accuracy: 0.8874 - val_loss: 0.8097 - val_accuracy: 0.7826\n",
      "Epoch 64/100\n",
      "1407/1407 [==============================] - 76s 54ms/step - loss: 0.3187 - accuracy: 0.8941 - val_loss: 0.8459 - val_accuracy: 0.7818\n",
      "Epoch 65/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.3284 - accuracy: 0.8901 - val_loss: 0.8457 - val_accuracy: 0.7858\n",
      "Epoch 66/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.3201 - accuracy: 0.8930 - val_loss: 0.8308 - val_accuracy: 0.7862\n",
      "Epoch 67/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.3273 - accuracy: 0.8909 - val_loss: 0.8437 - val_accuracy: 0.7826\n",
      "Epoch 68/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.3184 - accuracy: 0.8926 - val_loss: 0.8602 - val_accuracy: 0.7812\n",
      "Epoch 69/100\n",
      "1407/1407 [==============================] - 75s 54ms/step - loss: 0.3308 - accuracy: 0.8910 - val_loss: 0.7994 - val_accuracy: 0.7878\n",
      "Epoch 70/100\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.3227 - accuracy: 0.8923 - val_loss: 0.8169 - val_accuracy: 0.7908\n",
      "Epoch 71/100\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.3216 - accuracy: 0.8925 - val_loss: 0.8866 - val_accuracy: 0.7932\n",
      "Epoch 72/100\n",
      "1407/1407 [==============================] - 74s 52ms/step - loss: 0.3103 - accuracy: 0.8962 - val_loss: 0.8934 - val_accuracy: 0.7868\n",
      "Epoch 73/100\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.3214 - accuracy: 0.8930 - val_loss: 0.8394 - val_accuracy: 0.7910\n",
      "Epoch 74/100\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.3226 - accuracy: 0.8925 - val_loss: 0.9010 - val_accuracy: 0.7764\n",
      "Epoch 75/100\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.3171 - accuracy: 0.8945 - val_loss: 0.8416 - val_accuracy: 0.7850\n",
      "Epoch 76/100\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.3153 - accuracy: 0.8961 - val_loss: 0.8542 - val_accuracy: 0.7878\n",
      "Epoch 77/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.3160 - accuracy: 0.8948 - val_loss: 0.8422 - val_accuracy: 0.7842\n",
      "Epoch 78/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.3241 - accuracy: 0.8933 - val_loss: 0.8418 - val_accuracy: 0.7834\n",
      "Epoch 79/100\n",
      "1407/1407 [==============================] - 75s 54ms/step - loss: 0.3089 - accuracy: 0.8976 - val_loss: 0.8228 - val_accuracy: 0.7832\n",
      "Epoch 80/100\n",
      "1407/1407 [==============================] - 76s 54ms/step - loss: 0.3132 - accuracy: 0.8979 - val_loss: 0.8337 - val_accuracy: 0.7878\n",
      "Epoch 81/100\n",
      "1407/1407 [==============================] - 76s 54ms/step - loss: 0.3122 - accuracy: 0.8976 - val_loss: 0.8815 - val_accuracy: 0.7800\n",
      "Epoch 82/100\n",
      "1407/1407 [==============================] - 76s 54ms/step - loss: 0.3046 - accuracy: 0.8990 - val_loss: 0.8282 - val_accuracy: 0.7962\n",
      "Epoch 83/100\n",
      "1407/1407 [==============================] - 76s 54ms/step - loss: 0.3115 - accuracy: 0.8975 - val_loss: 0.8987 - val_accuracy: 0.7846\n",
      "Epoch 84/100\n",
      "1407/1407 [==============================] - 75s 54ms/step - loss: 0.2991 - accuracy: 0.9020 - val_loss: 0.8528 - val_accuracy: 0.7840\n",
      "Epoch 85/100\n",
      "1407/1407 [==============================] - 76s 54ms/step - loss: 0.3066 - accuracy: 0.9002 - val_loss: 0.9329 - val_accuracy: 0.7942\n",
      "Epoch 86/100\n",
      "1407/1407 [==============================] - 76s 54ms/step - loss: 0.3084 - accuracy: 0.8982 - val_loss: 0.9241 - val_accuracy: 0.7834\n",
      "Epoch 87/100\n",
      "1407/1407 [==============================] - 76s 54ms/step - loss: 0.3078 - accuracy: 0.9008 - val_loss: 0.9026 - val_accuracy: 0.7844\n",
      "Epoch 88/100\n",
      "1407/1407 [==============================] - 76s 54ms/step - loss: 0.3075 - accuracy: 0.9006 - val_loss: 0.8942 - val_accuracy: 0.7780\n",
      "Epoch 89/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.3062 - accuracy: 0.9004 - val_loss: 0.9322 - val_accuracy: 0.7870\n",
      "Epoch 90/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.3008 - accuracy: 0.9017 - val_loss: 0.8712 - val_accuracy: 0.7738\n",
      "Epoch 91/100\n",
      "1407/1407 [==============================] - 75s 54ms/step - loss: 0.3001 - accuracy: 0.9027 - val_loss: 0.8964 - val_accuracy: 0.7888\n",
      "Epoch 92/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.3000 - accuracy: 0.9012 - val_loss: 0.8626 - val_accuracy: 0.7792\n",
      "Epoch 93/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.3104 - accuracy: 0.8997 - val_loss: 0.8411 - val_accuracy: 0.7846\n",
      "Epoch 94/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.3017 - accuracy: 0.9008 - val_loss: 0.8816 - val_accuracy: 0.7894\n",
      "Epoch 95/100\n",
      "1407/1407 [==============================] - 76s 54ms/step - loss: 0.3015 - accuracy: 0.9023 - val_loss: 0.8243 - val_accuracy: 0.7910\n",
      "Epoch 96/100\n",
      "1407/1407 [==============================] - 76s 54ms/step - loss: 0.2953 - accuracy: 0.9034 - val_loss: 0.8750 - val_accuracy: 0.7852\n",
      "Epoch 97/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.3048 - accuracy: 0.9007 - val_loss: 1.0153 - val_accuracy: 0.7874\n",
      "Epoch 98/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.3004 - accuracy: 0.9029 - val_loss: 0.8347 - val_accuracy: 0.7830\n",
      "Epoch 99/100\n",
      "1407/1407 [==============================] - 75s 54ms/step - loss: 0.3055 - accuracy: 0.9003 - val_loss: 0.9000 - val_accuracy: 0.7930\n",
      "Epoch 100/100\n",
      "1407/1407 [==============================] - 76s 54ms/step - loss: 0.3034 - accuracy: 0.9004 - val_loss: 1.0069 - val_accuracy: 0.7878\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 481.2985 - accuracy: 0.5414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[481.2984619140625, 0.5414000153541565]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_size = 4 # размер ядра в свертывающих слоях\n",
    "\n",
    "inp = Input(shape=(depth, height, width))\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "conv_1 = Convolution2D(conv_depth_1, (kernel_size, kernel_size), padding='same', activation='relu')(inp)\n",
    "conv_2 = Convolution2D(conv_depth_1, (kernel_size, kernel_size), padding='same', activation='relu')(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size), padding='same')(conv_2)\n",
    "drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
    "conv_3 = Convolution2D(conv_depth_2, (kernel_size, kernel_size), padding='same', activation='relu')(drop_1)\n",
    "conv_4 = Convolution2D(conv_depth_2, (kernel_size, kernel_size), padding='same', activation='relu')(conv_3)\n",
    "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size), padding='same')(conv_4)\n",
    "drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "# Now flatten to 1D, apply FC -> ReLU (with dropout) -> softmax\n",
    "flat = Flatten()(drop_2) # Трансформируем в одномерный вектор\n",
    "hidden = Dense(hidden_size, activation='relu')(flat)\n",
    "drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "out = Dense(num_classes, activation='softmax')(drop_3)\n",
    "\n",
    "model = Model(inp, out) # Укажем слой входа и слой выхода\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "          verbose=1, validation_split=0.1) # Оставляем 10 процентов для тестирования\n",
    "\n",
    "model.evaluate(X_test, Y_test, verbose=1) # Оценим обученную модель на тестовых данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309506e0",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "\n",
    "В результате выполнения лабораторной работы можно сделать вывод о том, что от параметра DropOut напрямую зависит результат обучения модели, если указать слишком большую вероятность отключения нейрона, модель может неккоректно обучиться. При уменьшении размера ядра заметно ухудшается точность при оценке модели, а также увеличиваются потери и уменьшается точность обучения, но заметно уменьшается время компиляции. А при увеличении размера, наоборот, точность увеличивается, как и время компиляции, а потери уменьшаются."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
